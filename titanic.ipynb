{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a2aea1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-29T14:46:47.797243Z",
     "iopub.status.busy": "2021-12-29T14:46:47.796118Z",
     "iopub.status.idle": "2021-12-29T14:46:48.809505Z",
     "shell.execute_reply": "2021-12-29T14:46:48.808782Z",
     "shell.execute_reply.started": "2021-12-29T14:35:56.808651Z"
    },
    "papermill": {
     "duration": 1.023904,
     "end_time": "2021-12-29T14:46:48.809715",
     "exception": false,
     "start_time": "2021-12-29T14:46:47.785811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "train_df = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/titanic/test.csv\")\n",
    "submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d44f19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T14:46:48.830868Z",
     "iopub.status.busy": "2021-12-29T14:46:48.830258Z",
     "iopub.status.idle": "2021-12-29T14:46:48.846967Z",
     "shell.execute_reply": "2021-12-29T14:46:48.847417Z",
     "shell.execute_reply.started": "2021-12-29T14:35:58.038865Z"
    },
    "papermill": {
     "duration": 0.030901,
     "end_time": "2021-12-29T14:46:48.847591",
     "exception": false,
     "start_time": "2021-12-29T14:46:48.816690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93306ee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T14:46:48.867046Z",
     "iopub.status.busy": "2021-12-29T14:46:48.863320Z",
     "iopub.status.idle": "2021-12-29T14:46:48.869172Z",
     "shell.execute_reply": "2021-12-29T14:46:48.869605Z",
     "shell.execute_reply.started": "2021-12-29T14:35:58.067562Z"
    },
    "papermill": {
     "duration": 0.015516,
     "end_time": "2021-12-29T14:46:48.869767",
     "exception": false,
     "start_time": "2021-12-29T14:46:48.854251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b3f3d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T14:46:48.892013Z",
     "iopub.status.busy": "2021-12-29T14:46:48.891390Z",
     "iopub.status.idle": "2021-12-29T14:46:48.922185Z",
     "shell.execute_reply": "2021-12-29T14:46:48.921648Z",
     "shell.execute_reply.started": "2021-12-29T14:35:58.080516Z"
    },
    "papermill": {
     "duration": 0.045941,
     "end_time": "2021-12-29T14:46:48.922320",
     "exception": false,
     "start_time": "2021-12-29T14:46:48.876379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e19d8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T14:46:48.939886Z",
     "iopub.status.busy": "2021-12-29T14:46:48.939112Z",
     "iopub.status.idle": "2021-12-29T14:46:50.444339Z",
     "shell.execute_reply": "2021-12-29T14:46:50.444842Z",
     "shell.execute_reply.started": "2021-12-29T14:35:58.134311Z"
    },
    "papermill": {
     "duration": 1.515619,
     "end_time": "2021-12-29T14:46:50.445016",
     "exception": false,
     "start_time": "2021-12-29T14:46:48.929397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 283, number of negative: 429\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.397472 -> initscore=-0.416010\n",
      "[LightGBM] [Info] Start training from score -0.416010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.437028\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.375283\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's binary_logloss: 0.364539\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's binary_logloss: 0.365512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.364317\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's binary_logloss: 0.362446\n",
      "[LightGBM] [Info] Number of positive: 283, number of negative: 429\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.397472 -> initscore=-0.416010\n",
      "[LightGBM] [Info] Start training from score -0.416010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.442753\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.373292\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's binary_logloss: 0.361446\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's binary_logloss: 0.361822\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's binary_logloss: 0.360824\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 358\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 206\n",
      "[LightGBM] [Info] Number of data points in the train set: 594, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.397306 -> initscore=-0.416701\n",
      "[LightGBM] [Info] Start training from score -0.416701\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.503031\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.466354\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's binary_logloss: 0.45598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's binary_logloss: 0.454442\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.455439\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's binary_logloss: 0.457931\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's binary_logloss: 0.454117\n",
      "0.8181818181818182\n",
      "[LightGBM] [Info] Number of positive: 214, number of negative: 380\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 207\n",
      "[LightGBM] [Info] Number of data points in the train set: 594, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.360269 -> initscore=-0.574195\n",
      "[LightGBM] [Info] Start training from score -0.574195\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.482153\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.435696\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's binary_logloss: 0.421185\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's binary_logloss: 0.422292\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.422375\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's binary_logloss: 0.419997\n",
      "0.8114478114478114\n",
      "[LightGBM] [Info] Number of positive: 234, number of negative: 360\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 208\n",
      "[LightGBM] [Info] Number of data points in the train set: 594, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393939 -> initscore=-0.430783\n",
      "[LightGBM] [Info] Start training from score -0.430783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.471119\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.409435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's binary_logloss: 0.388307\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's binary_logloss: 0.38208\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.378166\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's binary_logloss: 0.373974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's binary_logloss: 0.373599\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's binary_logloss: 0.375705\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.373419\n",
      "0.835016835016835\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df[\"Sex\"].value_counts()\n",
    "\n",
    "# train_df[\"Embarked\"].value_counts()\n",
    "\n",
    "# train_df[\"Cabin\"].value_counts()\n",
    "\n",
    "# train_df.isnull().sum()\n",
    "\n",
    "# test_df.describe()\n",
    "\n",
    "# test_df.isnull().sum()\n",
    "\n",
    "train_df[[\"Embarked\",\"Survived\",\"PassengerId\"]].dropna()\n",
    "\n",
    "embarked_df = train_df[[\"Embarked\",\"Survived\",\"PassengerId\"]].dropna().groupby([\"Embarked\",\"Survived\"]).count().unstack()\n",
    "# embarked_df.plot.bar(stacked=True)\n",
    "\n",
    "embarked_df[\"survived_rate\"]=embarked_df.iloc[:,0]/(embarked_df.iloc[:,0] + embarked_df.iloc[:,1])\n",
    "#embarked_df\n",
    "\n",
    "# p.099\n",
    "sex_df = train_df[[\"Sex\", \"Survived\", \"PassengerId\"]].dropna().groupby([\"Sex\", \"Survived\"]).count().unstack()\n",
    "#sex_df.plot.bar(stacked=True)\n",
    "\n",
    "# p.100\n",
    "ticket_df = train_df[[\"Pclass\",\"Survived\",\"PassengerId\"]].dropna().groupby([\"Pclass\",\"Survived\"]).count().unstack()\n",
    "# ticket_df.plot.bar(stacked=True)\n",
    "\n",
    "# p.101\n",
    "# ValueError\n",
    "#plt.hist((train_df[train_df[\"Survived\"] == 0][[\"Age\"]].values, train_df[train_df[\"Survived\"] == 1][[\"Age\"]].values), \n",
    "#         histtype=\"barstacked\", bins=8, label=(\"Death\", \"Survive\"))\n",
    "#plt.legend()\n",
    "\n",
    "train_df_corr = pd.get_dummies(train_df, columns=[\"Sex\"], drop_first=True)\n",
    "train_df_corr = pd.get_dummies(train_df_corr, columns=[\"Embarked\"])\n",
    "\n",
    "# p.104-p.104\n",
    "train_corr = train_df_corr.corr()\n",
    "# train_corr\n",
    "#plt.figure(figsize=(9,9))\n",
    "#sns.heatmap(train_corr, vmax=1, vmin=-1, center=0, annot=True)\n",
    "\n",
    "# p.106\n",
    "all_df = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n",
    "\n",
    "# p.107\n",
    "# all_df.isnull().sum()\n",
    "\n",
    "# p.108\n",
    "Fare_mean = all_df[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").mean().reset_index()\n",
    "Fare_mean.columns = [\"Pclass\", \"Fare_mean\"]\n",
    "\n",
    "# p.109\n",
    "all_df = pd.merge(all_df, Fare_mean, on=\"Pclass\", how=\"left\")\n",
    "all_df.loc[(all_df[\"Fare\"].isnull()), \"Fare\"] = all_df[\"Fare_mean\"]\n",
    "all_df = all_df.drop(\"Fare_mean\", axis=1)\n",
    "\n",
    "# p.111\n",
    "name_df = all_df[\"Name\"].str.split(\"[,.]\",2,expand=True)\n",
    "name_df.columns = [\"family_name\", \"honorific\", \"name\"]\n",
    "name_df[\"family_name\"] = name_df[\"family_name\"].str.strip()\n",
    "name_df[\"honorific\"] = name_df[\"honorific\"].str.strip()\n",
    "name_df[\"name\"] = name_df[\"name\"].str.strip()\n",
    "\n",
    "# p.112 \n",
    "name_df[\"honorific\"].value_counts()\n",
    "\n",
    "# p.113 \n",
    "all_df = pd.concat([all_df, name_df], axis=1)\n",
    "\n",
    "# p.115 \n",
    "#plt.figure(figsize=(18, 5))\n",
    "#sns.boxplot(x=\"honorific\", y=\"Age\", data=all_df)\n",
    "\n",
    "# \n",
    "#all_df[[\"Age\", \"honorific\"]].groupby(\"honorific\").mean()\n",
    "\n",
    "# p.116 \n",
    "train_df = pd.concat([train_df, name_df[0:len(train_df)].reset_index(drop=True)], axis=1)\n",
    "test_df = pd.concat([test_df, name_df[len(train_df):].reset_index(drop=True)], axis=1)\n",
    "honorific_df = train_df[[\"honorific\", \"Survived\", \"PassengerId\"]].dropna().groupby([\"honorific\", \"Survived\"]).count().unstack()\n",
    "#honorific_df.plot.bar(stacked=True)\n",
    "\n",
    "# p.118 \n",
    "honorific_age_mean = all_df[[\"honorific\", \"Age\"]].groupby(\"honorific\").mean().reset_index()\n",
    "honorific_age_mean.columns = [\"honorific\", \"honorific_Age\"]\n",
    "all_df = pd.merge(all_df, honorific_age_mean, on=\"honorific\", how=\"left\")\n",
    "all_df.loc[(all_df[\"Age\"].isnull()), \"Age\"] = all_df[\"honorific_Age\"]\n",
    "all_df = all_df.drop([\"honorific_Age\"], axis=1)\n",
    "\n",
    "# \n",
    "all_df[\"family_num\"] = all_df[\"Parch\"] + all_df[\"SibSp\"]\n",
    "#all_df[\"family_num\"].value_counts()\n",
    "\n",
    "# p.119 01alone\n",
    "all_df.loc[all_df[\"family_num\"]==0, \"alone\"] = 1\n",
    "all_df[\"alone\"].fillna(0, inplace=True)\n",
    "\n",
    "# \n",
    "all_df = all_df.drop([\"PassengerId\", \"Name\", \"family_name\", \"name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "# p.120 \n",
    "categories = all_df.columns[all_df.dtypes == \"object\"]\n",
    "# print(categories)\n",
    "\n",
    "# Mr, Miss, Mrs, Masterother\n",
    "all_df.loc[~((all_df[\"honorific\"]==\"Mr\") | (all_df[\"honorific\"]==\"Miss\") | (all_df[\"honorific\"]==\"Mrs\") | (all_df[\"honorific\"]==\"Master\")), \"honorific\"] = \"other\"\n",
    "# all_df.honorific.value_counts()\n",
    "\n",
    "# p.121 :Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(all_df[\"Sex\"])\n",
    "all_df[\"Sex\"] = le.transform(all_df[\"Sex\"])\n",
    "\n",
    "# p.123 categoriesLabel Encoding\n",
    "for cat in categories:\n",
    "    le = LabelEncoder()\n",
    "    #print(cat)\n",
    "    if all_df[cat].dtypes == \"object\":\n",
    "        le = le.fit(all_df[cat])\n",
    "        all_df[cat] = le.transform(all_df[cat])\n",
    "all_df.head()\n",
    "\n",
    "# p.124 \n",
    "train_X = all_df[~all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "train_Y = train_df[\"Survived\"]\n",
    "\n",
    "test_X = all_df[all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "\n",
    "# p.125 \n",
    "import lightgbm as lgb\n",
    "\n",
    "# p. 131 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 20%\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_Y, test_size=0.2)\n",
    "\n",
    "# LightGBM\n",
    "categories = [\"Embarked\", \"Pclass\", \"Sex\", \"honorific\", \"alone\"]\n",
    "lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categories)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, categorical_feature=categories, reference=lgb_train)\n",
    "\n",
    "# p.132 \n",
    "lgbm_params = {\n",
    "    \"objective\":\"binary\", # 2\n",
    "    \"random_seed\":1234\n",
    "}\n",
    "\n",
    "# LightGBM\n",
    "# early_stopping_rounds, verbose_eval  deprecated \n",
    "model_lgb = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval, num_boost_round=100, early_stopping_rounds=20, verbose_eval=10)\n",
    "\n",
    "# p.133 \n",
    "#model_lgb.feature_importance()\n",
    "importance = pd.DataFrame(model_lgb.feature_importance(), index=X_train.columns, columns=[\"importance\"]).sort_values(by=\"importance\", ascending=True)\n",
    "#importance.plot.barh()\n",
    "\n",
    "# p.135 \n",
    "y_pred = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n",
    "\n",
    "# p.136 accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "#accuracy_score(y_valid, np.round(y_pred))\n",
    "\n",
    "# \n",
    "lgbm_params = {\n",
    "    \"objective\":\"binary\",\n",
    "    \"max_bin\":331,\n",
    "    \"num_leaves\": 20,\n",
    "    \"min_data_in_leaf\": 57,\n",
    "    \"random_seed\": 1234\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categories)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, categorical_feature=categories, reference=lgb_train)\n",
    "model_lgb = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval, num_boost_round=100, early_stopping_rounds=20, verbose_eval=10)\n",
    "\n",
    "y_pred = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n",
    "accuracy_score(y_valid, np.round(y_pred))\n",
    "\n",
    "# p.138 \n",
    "folds = 3\n",
    "kf = KFold(n_splits=folds)\n",
    "models = []\n",
    "for train_index, val_index in kf.split(train_X):\n",
    "    X_train = train_X.iloc[train_index]\n",
    "    X_valid = train_X.iloc[val_index]\n",
    "    y_train = train_Y.iloc[train_index]\n",
    "    y_valid = train_Y.iloc[val_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categories)\n",
    "    lgb_eval = lgb.Dataset(X_valid, y_valid, categorical_feature=categories, reference=lgb_train)\n",
    "    model_lgb = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval, num_boost_round=100, early_stopping_rounds=20, verbose_eval=10)\n",
    "    y_pred = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n",
    "    print(accuracy_score(y_valid, np.round(y_pred)))\n",
    "    models.append(model_lgb)\n",
    "    \n",
    "# p.141 \n",
    "preds = []\n",
    "\n",
    "for model in models:\n",
    "    pred = model.predict(test_X)\n",
    "    preds.append(pred)\n",
    "    \n",
    "preds_array = np.array(preds)\n",
    "preds_mean = np.mean(preds_array, axis=0)\n",
    "preds_int = (preds_mean > 0.5).astype(int)\n",
    "submission[\"Survived\"] = preds_int\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56569624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T14:46:50.477777Z",
     "iopub.status.busy": "2021-12-29T14:46:50.477017Z",
     "iopub.status.idle": "2021-12-29T14:46:50.558723Z",
     "shell.execute_reply": "2021-12-29T14:46:50.559156Z",
     "shell.execute_reply.started": "2021-12-29T14:42:57.609114Z"
    },
    "papermill": {
     "duration": 0.104605,
     "end_time": "2021-12-29T14:46:50.559332",
     "exception": false,
     "start_time": "2021-12-29T14:46:50.454727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>10.594057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>7.531944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>16.218712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fare\n",
       "Embarked           \n",
       "C         10.594057\n",
       "Q          7.531944\n",
       "S         16.218712"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p.149 \n",
    "train_df = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/titanic/test.csv\")\n",
    "all_df = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n",
    "#all_df.Pclass.value_counts()\n",
    "#all_df.Pclass.value_counts().plot.bar()\n",
    "\n",
    "# p.150 \n",
    "#all_df[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").describe()\n",
    "\n",
    "#plt.figure(figsize=(6, 5))\n",
    "#sns.boxplot(x=\"Pclass\", y=\"Fare\", data=all_df)\n",
    "\n",
    "# p.152 1(125%PClass0\n",
    "# Pclass2Fare1080\n",
    "all_df[\"Pclass2\"] = all_df[\"Pclass\"]\n",
    "all_df.loc[all_df[\"Fare\"]>108, \"Pclass2\"] = 0\n",
    "#all_df[all_df[\"Pclass2\"] == 0]\n",
    "\n",
    "# p.153 \n",
    "all_df[[\"Pclass2\", \"Age\"]].groupby(\"Pclass2\").describe()\n",
    "#plt.figure(figsize=(6, 5))\n",
    "#sns.boxplot(x=\"Pclass2\", y=\"Age\", data=all_df)\n",
    "\n",
    "# 15\n",
    "all_df[all_df[\"Age\"]>15][[\"Pclass2\",\"Age\"]].groupby(\"Pclass2\").describe()\n",
    "#plt.figure(figsize=(6, 5))\n",
    "#sns.boxplot(x=\"Pclass2\", y=\"Age\", data=all_df[all_df[\"Age\"]>15])\n",
    "\n",
    "#all_df.plot.scatter(x=\"Age\", y=\"Fare\", alpha=0.5)\n",
    "\n",
    "# p.156 \n",
    "all_df[\"family_num\"] = all_df[\"SibSp\"] + all_df[\"Parch\"]\n",
    "#all_df[[\"Pclass2\", \"family_num\"]].groupby(\"Pclass2\").describe()\n",
    "\n",
    "#plt.figure(figsize=(6, 5))\n",
    "#sns.boxplot(x=\"Pclass2\", y=\"family_num\", data=all_df)\n",
    "\n",
    "# p.158 \n",
    "Pclass_gender_df = all_df[[\"Pclass2\", \"Sex\", \"PassengerId\"]].dropna().groupby([\"Pclass2\", \"Sex\"]).count().unstack()\n",
    "#Pclass_gender_df.plot.bar(stacked=True)\n",
    "\n",
    "Pclass_gender_df[\"male_ratio\"] = Pclass_gender_df[\"PassengerId\", \"male\"]/(Pclass_gender_df[\"PassengerId\", \"male\"] + Pclass_gender_df[\"PassengerId\", \"female\"])\n",
    "#Pclass_gender_df\n",
    "\n",
    "# p.159 \n",
    "Pclass_emb_df = all_df[[\"Pclass2\",\"Embarked\",\"PassengerId\"]].dropna().groupby([\"Pclass2\", \"Embarked\"]).count().unstack()\n",
    "Pclass_emb_df = Pclass_emb_df.fillna(0)\n",
    "#Pclass_emb_df.plot.bar(stacked=True)\n",
    "Pclass_emb_df_ratio = Pclass_emb_df.copy()\n",
    "Pclass_emb_df_ratio[\"sum\"] = Pclass_emb_df_ratio[\"PassengerId\", \"C\"] + Pclass_emb_df_ratio[\"PassengerId\", \"Q\"] + Pclass_emb_df_ratio[\"PassengerId\", \"S\"]\n",
    "Pclass_emb_df_ratio[\"PassengerId\", \"C\"] = Pclass_emb_df_ratio[\"PassengerId\", \"C\"] / Pclass_emb_df_ratio[\"sum\"]\n",
    "Pclass_emb_df_ratio[\"PassengerId\", \"Q\"] = Pclass_emb_df_ratio[\"PassengerId\", \"Q\"] / Pclass_emb_df_ratio[\"sum\"]\n",
    "Pclass_emb_df_ratio[\"PassengerId\", \"S\"] = Pclass_emb_df_ratio[\"PassengerId\", \"S\"] / Pclass_emb_df_ratio[\"sum\"]\n",
    "Pclass_emb_df_ratio = Pclass_emb_df_ratio.drop([\"sum\"],axis=1)\n",
    "#Pclass_emb_df_ratio\n",
    "#Pclass_emb_df_ratio.plot.bar(stacked=True)\n",
    "\n",
    "# p.162 \n",
    "C_young10 = all_df[(all_df[\"Embarked\"]==\"C\") & (all_df[\"Age\"] // 10 == 1) & (all_df[\"family_num\"] == 0)]\n",
    "C_young20 = all_df[(all_df[\"Embarked\"]==\"C\") & (all_df[\"Age\"] // 10 == 2) & (all_df[\"family_num\"] == 0)]\n",
    "#len(C_young10)\n",
    "#len(C_young20)\n",
    "\n",
    "# p.163 Cherbourg\n",
    "# 3.91 Cherbourg1(10)\n",
    "#ax = all_df.plot.scatter(x=\"Age\", y=\"Fare\", alpha=0.5)\n",
    "#C_young10.plot.scatter(x=\"Age\", y=\"Fare\", color=\"red\", alpha=0.5, ax=ax)\n",
    "\n",
    "# 3.92 1Cherbourg1(10)\n",
    "#ax = all_df[all_df[\"family_num\"] == 0].plot.scatter(x=\"Age\", y=\"Fare\", alpha=0.5)\n",
    "#C_young10.plot.scatter(x=\"Age\", y=\"Fare\", color=\"red\", alpha=0.5, ax=ax)\n",
    "\n",
    "# 3.93 Cherbourg120\n",
    "#ax = all_df.plot.scatter(x=\"Age\", y=\"Fare\", alpha=0.5)\n",
    "#C_young20.plot.scatter(x=\"Age\", y=\"Fare\", color=\"red\", alpha=0.5, ax=ax)\n",
    "\n",
    "#ax = all_df[all_df[\"family_num\"] == 0].plot.scatter(x=\"Age\", y=\"Fare\", alpha=0.5)\n",
    "#C_young20.plot.scatter(x=\"Age\", y=\"Fare\", color=\"red\", alpha=0.5, ax=ax)\n",
    "\n",
    "# p.166 4 Cherbourg\n",
    "#C_all = all_df[(all_df[\"Embarked\"] == \"C\")]\n",
    "#ax = all_df.plot.scatter(x=\"Age\", y=\"Fare\", alpha=0.5)\n",
    "#C_all.plot.scatter(x=\"Age\", y=\"Fare\", color=\"red\", alpha=0.5, ax=ax)\n",
    "\n",
    "# p.167 101\n",
    "all_df[(all_df[\"Age\"] // 10 == 1) & (all_df[\"family_num\"] == 0)][[\"Embarked\", \"Fare\"]].groupby(\"Embarked\").mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.081416,
   "end_time": "2021-12-29T14:46:51.279107",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-29T14:46:38.197691",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
