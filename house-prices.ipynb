{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# p.176 必要なライブラリをインポートする\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use(\"ggplot\")\n\n# p.178 ランダムシードの設定\nimport random\nnp.random.seed(1234)\nrandom.seed(1234)\n\n# p.184 LabelEncoderのライブラリをインポート\nfrom sklearn.preprocessing import LabelEncoder\n\n# p.188 LightGBMのライブラリをインポート\nimport lightgbm as lgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-30T15:06:51.198079Z","iopub.execute_input":"2021-12-30T15:06:51.198699Z","iopub.status.idle":"2021-12-30T15:06:51.211658Z","shell.execute_reply.started":"2021-12-30T15:06:51.198658Z","shell.execute_reply":"2021-12-30T15:06:51.210487Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# p.179 CSVデータを読み込む\ntrain_df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\ntest_df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\nsubmission = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\n\n# train_df.head()\n\n# p.180 学習データの各変数の型を確認する\n# train_df.dtypes\n\n# p.181 MSZoningの各分類ごとの個数を確認する\n# train_df[\"MSZoning\"].value_counts()\n\n# p.182 学習データとテストデータの連結\nall_df = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n# all_df\n\n# p.183 目的変数であるSalePriceの値を確認\n# all_df[\"SalePrice\"]\n\n# object型の変数を取得\ncategories = all_df.columns[all_df.dtypes == \"object\"]\n# print(categories)\n\n# p.185 'Alley'の各分類の個数を確認\n# all_df[\"Alley\"].value_counts()\n\n# 欠損値を数値に変換する\nfor cat in categories:\n    le = LabelEncoder()\n    # print(cat)\n    all_df[cat].fillna(\"missing\", inplace=True)\n    le = le.fit(all_df[cat])\n    all_df[cat] = le.transform(all_df[cat])\n    all_df[cat] = all_df[cat].astype(\"category\")\n# all_df\n\n# p.188 データをtrain_dfとtest_dfに戻す\ntrain_df_le = all_df[~all_df[\"SalePrice\"].isnull()]\ntest_df_le = all_df[all_df[\"SalePrice\"].isnull()]\n# train_df_le.head()\n# test_df_le.head()\n\n# p.189 クロスバリデーション用のライブラリを読み込んで分割数を3に設定\nfrom sklearn.model_selection import KFold\nfolds = 3\nkf = KFold(n_splits=folds)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T15:06:51.294126Z","iopub.execute_input":"2021-12-30T15:06:51.294627Z","iopub.status.idle":"2021-12-30T15:06:51.517516Z","shell.execute_reply.started":"2021-12-30T15:06:51.294570Z","shell.execute_reply":"2021-12-30T15:06:51.516425Z"},"trusted":true},"execution_count":19,"outputs":[]}]}