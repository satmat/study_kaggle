{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# p.176 必要なライブラリをインポートする\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use(\"ggplot\")\n\n# p.178 ランダムシードの設定\nimport random\nnp.random.seed(1234)\nrandom.seed(1234)\n\n# p.184 LabelEncoderのライブラリをインポート\nfrom sklearn.preprocessing import LabelEncoder\n\n# p.188 LightGBMのライブラリをインポート\nimport lightgbm as lgb\n\n# リスト4.17 LightGBMのハイパーパラメータを設定\nlgbm_params = {\n    \"objective\":\"regression\",\n    \"random_seed\":1234\n}\n\n# p.189 クロスバリデーション用のライブラリを読み込んで分割数を3に設定\nfrom sklearn.model_selection import KFold\nfolds = 3\nkf = KFold(n_splits=folds)\n\n# p.190 リスト4.19 平均二乗誤差を出すライブラリをインポート\nfrom sklearn.metrics import mean_squared_error\n\n# p.234 リスト4.65 Optunaのライブラリのインポート\nimport optuna\n\n# p.235 リスト4.66 学習データと検証データを作成\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-06T08:20:21.567550Z","iopub.execute_input":"2022-01-06T08:20:21.567909Z","iopub.status.idle":"2022-01-06T08:20:21.581136Z","shell.execute_reply.started":"2022-01-06T08:20:21.567877Z","shell.execute_reply":"2022-01-06T08:20:21.580186Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# p.179 CSVデータを読み込む\ntrain_df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\ntest_df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\nsubmission = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\n\n# train_df.head()\n\n# p.180 学習データの各変数の型を確認する\n# train_df.dtypes\n\n# p.181 MSZoningの各分類ごとの個数を確認する\n# train_df[\"MSZoning\"].value_counts()\n\n# p.182 学習データとテストデータの連結\nall_df = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n# all_df\n\n# p.183 目的変数であるSalePriceの値を確認\n# all_df[\"SalePrice\"]\n\n# object型の変数を取得\ncategories = all_df.columns[all_df.dtypes == \"object\"]\n# print(categories)\n\n# p.185 'Alley'の各分類の個数を確認\n# all_df[\"Alley\"].value_counts()\n\n# 欠損値を数値に変換する\nfor cat in categories:\n    le = LabelEncoder()\n    # print(cat)\n    all_df[cat].fillna(\"missing\", inplace=True)\n    le = le.fit(all_df[cat])\n    all_df[cat] = le.transform(all_df[cat])\n    all_df[cat] = all_df[cat].astype(\"category\")\n# all_df\n\n# p.188 データをtrain_dfとtest_dfに戻す\n#train_df_le = all_df[~all_df[\"SalePrice\"].isnull()]\n#test_df_le = all_df[all_df[\"SalePrice\"].isnull()]\n# train_df_le.head()\n# test_df_le.head()\n\n# リスト4.18 説明変数、目的変数を指定\n#train_X = train_df_le.drop([\"SalePrice\", \"Id\"], axis=1)\n#train_Y = train_df_le[\"SalePrice\"]\n\n# p.190 リスト4.20 各foldごとに作成したモデルごとの予測値を保存\n#models = []\n#rmses = []\n#oof = np.zeros(len(train_X))\n\n#for train_index, val_index in kf.split(train_X):\n#    X_train = train_X.iloc[train_index]\n#    X_valid = train_X.iloc[val_index]\n#    y_train = train_Y.iloc[train_index]\n#    y_valid = train_Y.iloc[val_index]\n    \n#    lgb_train = lgb.Dataset(X_train, y_train)\n#    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n#    model_lgb = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval, num_boost_round=100, early_stopping_rounds=20, verbose_eval=10,)\n    \n#    y_pred = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n#    tmp_rmse = np.sqrt(mean_squared_error(np.log(y_valid), np.log(y_pred)))\n#    print(tmp_rmse)\n    \n#    models.append(model_lgb)\n#    rmses.append(tmp_rmse)\n#    oof[val_index] = y_pred\n    \n# p.192 平均RMSEを計算する\n# sum(rmses)/len(rmses)\n\n# p.193 statisticsライブラリから計算\n#from statistics import mean\n#mean(rmses)\n\n# p.193 現状の予測値と実際の値の違いを可視化\n#actual_pred_df = pd.DataFrame({\"actual\": train_Y, \"pred\": oof})\n#actual_pred_df.plot(figsize=(12,5))\n\n# p.194 各変数の重要度を確認する\n# リスト4.24 変数の数を制限して各変数の重要度を表示\n#for model in models:\n#    lgb.plot_importance(model, importance_type=\"gain\", max_num_features=15)\n\n# p.197 リスト4.25 SalePriceの各統計量を確認する\n#train_df[\"SalePrice\"].describe()\n\n# p.198 リスト4.26 ヒストグラムで分布を確認\n#train_df[\"SalePrice\"].plot.hist(bins=20)\n\n# p.199 リスト4.27 SalePriceを対数化\n#np.log(train_df['SalePrice'])\n\n# 対数化したSalePriceの分布をヒストグラムで可視化\n#np.log(train_df['SalePrice']).plot.hist(bins=20)\n\n# p.200 リスト4.29 対数化による予測精度の向上を確認\n#train_df_le[\"SalePrice_log\"] = np.log(train_df_le[\"SalePrice\"])\n#train_X = train_df_le.drop([\"SalePrice\", \"SalePrice_log\", \"Id\"], axis=1)\n#train_Y = train_df_le[\"SalePrice_log\"]\n\n#models = []\n#rmses = []\n#oof = np.zeros(len(train_X))\n\n#for train_index, val_index in kf.split(train_X):\n#    X_train = train_X.iloc[train_index]\n#    X_valid = train_X.iloc[val_index]\n#    y_train = train_Y.iloc[train_index]\n#    y_valid = train_Y.iloc[val_index]\n    \n#    lgb_train = lgb.Dataset(X_train, y_train)\n#    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n    \n#    model_lgb = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval, num_boost_round=100, early_stopping_rounds=20, verbose_eval=10,)\n    \n#    y_pred = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n#    tmp_rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n#    print(tmp_rmse)\n    \n#    models.append(model_lgb)\n#    rmses.append(tmp_rmse)\n#    oof[val_index] = y_pred\n    \n#sum(rmses)/len(rmses)\n\n# p.204 リスト4.30 all_dfの作成\nall_df = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\ncategories = all_df.columns[all_df.dtypes == \"object\"]\n#print(categories)\n\n# p.205 リスト4.31 欠損値の数が上位40の変数を確認\n#all_df.isnull().sum().sort_values(ascending=False).head(40)\n\n# p.207 リスト4.32 PoolQCの各分類ごとの個数\n#all_df.PoolQC.value_counts()\n\n# リスト4.33 PoolQCの値を値があるものを1、値がないものを0に変換\n#all_df.loc[~all_df[\"PoolQC\"].isnull(), \"PoolQC\"] = 1\n#all_df.loc[all_df[\"PoolQC\"].isnull(), \"PoolQC\"] = 0\n# all_df.PoolQC.value_counts()\n\n# p.208 リスト4.35 MiscFeature, Alleyも0と1に変換する\n#all_df.loc[~all_df[\"MiscFeature\"].isnull(), \"MiscFeature\"] = 1\n#all_df.loc[all_df[\"MiscFeature\"].isnull(), \"MiscFeature\"] = 0\n#all_df.loc[~all_df[\"Alley\"].isnull(), \"Alley\"] = 1\n#all_df.loc[~all_df[\"Alley\"].isnull(), \"Alley\"] = 0\n\n# リスト4.36 繰り返し処理はfor文でまとめる\nHighFacility_col = [\"PoolQC\", \"MiscFeature\", \"Alley\"]\nfor col in HighFacility_col:\n    if all_df[col].dtype == \"object\":\n        if len(all_df[all_df[col].isnull()]) > 0:\n            all_df.loc[~all_df[col].isnull(), col] = 1\n            all_df.loc[all_df[col].isnull(), col] = 0\n\n# p.209 リスト4.37 0か1の値に変換した各変数を足し合わせて、高級住宅設備の数という特徴量を作成\nall_df[\"hasHighFacility\"] = all_df[\"PoolQC\"] + all_df[\"MiscFeature\"] + all_df[\"Alley\"]\nall_df[\"hasHighFacility\"] = all_df[\"hasHighFacility\"].astype(int)\n# all_df.hasHighFacility.value_counts()\n\n# p.209 リスト4.39 もとのデータからPoolQC, MiscFeature, Alleyを削除\nall_df = all_df.drop([\"PoolQC\", \"MiscFeature\", \"Alley\"], axis=1)\n\n# p.211 リスト4.40 各変数の統計量を確認する\n#all_df.describe().T # 転置\n\n# p.212 リスト4.41 数値データのみの抜き出し\ntrain_df_num = train_df.select_dtypes(include=[np.number])\n\n# リスト4.42 比例尺度ではない変数\nnonratio_features = [\"Id\", \"MSSubClass\", \"OverallQual\", \"OverallCond\", \"YearRemodAdd\", \"MoSold\", \"YrSold\"]\n\n# リスト4.43 数値データからリスト4.43の変数を除いた比例尺度データ\nnum_features = sorted(list(set(train_df_num) - set(nonratio_features)))\n#num_features\n\n# p.213 リスト4.44 比例尺度の列のみを抜き出す\ntrain_df_num_rs = train_df_num[num_features]\n\n# p.214 リスト4.45 3/4分位数が0となる変数を確認\n#for col in num_features:\n#    if train_df_num_rs.describe()[col][\"75%\"] == 0:\n#        print(col, len(train_df_num_rs[train_df_num_rs[col] == 0]))\n\n# p.215 リスト4.46 ある特定の値のみしかとらないものを確認\n#for col in num_features:\n#    if train_df_num_rs[col].nunique() < 15:\n#        print(col, train_df_num_rs[col].nunique())\n        \n# リスト4.47 外れ値があるか確認\nfor col in num_features:\n    tmp_df = train_df_num_rs[(train_df_num_rs[col] > train_df_num_rs[col].mean() + train_df_num_rs[col].std()*3) | (train_df_num_rs[col] < train_df_num_rs[col].mean() - train_df_num_rs[col].std()*3)]\n#    print(col, len(tmp_df))\n \n# p.217 リスト4.48 BsmtFinSF1とSalePriceの分布を可視化\n#all_df.plot.scatter(x=\"BsmtFinSF1\", y=\"SalePrice\")\n\n# リスト4.49 BsmtFinSF1が広いもののSalePriceが高くないものを確認\n#all_df[all_df[\"BsmtFinSF1\"] > 5000]\n\n# p.218 TotalBsmtSFとSalePriceの分布を可視化\n# all_df.plot.scatter(x=\"TotalBsmtSF\", y=\"SalePrice\")\n# all_df[all_df[\"TotalBsmtSF\"] > 6000]\n\n# p.219 GrLivAreaとSalePriceの分布を可視化\n#all_df.plot.scatter(x=\"GrLivArea\", y=\"SalePrice\")\n#all_df[all_df[\"GrLivArea\"] > 5000]\n\n# p.219 1stFlrSFとSalePriceの分布を可視化\n#all_df.plot.scatter(x=\"1stFlrSF\", y=\"SalePrice\")\n#all_df[all_df[\"1stFlrSF\"] > 4000]\n\n# p.221 リスト4.53 外れ値以外を抽出（テストデータはすべて抽出）\nall_df = all_df[(all_df['BsmtFinSF1'] < 2000) | (all_df['SalePrice'].isnull())]\nall_df = all_df[(all_df['TotalBsmtSF'] < 3000) | (all_df['SalePrice'].isnull())]\nall_df = all_df[(all_df['GrLivArea'] < 4500) | (all_df['SalePrice'].isnull())]\nall_df = all_df[(all_df['1stFlrSF'] < 2500) | (all_df['SalePrice'].isnull())]\nall_df = all_df[(all_df['LotArea'] < 100000) | (all_df['SalePrice'].isnull())]\n\n# リスト4.54 categoriesの中から除外した3つの変数を削除\ncategories = categories.drop([\"PoolQC\", \"MiscFeature\", \"Alley\"])\n\n# リスト4.55 欠損値をmissingに置き換えてall_dfのカテゴリ変数をcategoryに設定\nfor cat in categories:\n    le = LabelEncoder()\n    #print(cat)\n    \n    all_df[cat].fillna(\"missing\", inplace=True)\n    le = le.fit(all_df[cat])\n    all_df[cat] = le.transform(all_df[cat])\n    all_df[cat] = all_df[cat].astype(\"category\")\n\n\n# p.228 リスト4.58 特徴量を追加\nall_df[\"Age\"] = all_df[\"YrSold\"] - all_df[\"YearBuilt\"]\n       \n# p.230 リスト4.61 広さの変数から追加するもの\nall_df[\"TotalSF\"] = all_df[\"TotalBsmtSF\"] + all_df[\"1stFlrSF\"] + all_df[\"2ndFlrSF\"]\nall_df[\"Total_Bathrooms\"] = all_df[\"FullBath\"] + all_df[\"HalfBath\"] + all_df[\"BsmtFullBath\"] + all_df[\"BsmtHalfBath\"]\n\n# リスト4.62 Porchの広さの合計も特徴量として追加\nall_df[\"Total_PorchSF\"] = all_df[\"WoodDeckSF\"] + all_df[\"OpenPorchSF\"] + all_df[\"EnclosedPorch\"] + all_df[\"3SsnPorch\"] + all_df[\"ScreenPorch\"]\n\n# リスト4.63 Porchの広さの合計をPorchがあるかないかの0,1の値に変換\nall_df[\"hasPorch\"] = all_df[\"Total_PorchSF\"].apply(lambda x: 1 if x > 0 else 0)\nall_df = all_df.drop(\"Total_PorchSF\", axis=1)   \n\n\n# p.223 リスト4.56 train_df_leとtest_df_leに分割\ntrain_df_le = all_df[~all_df[\"SalePrice\"].isnull()]\ntest_df_le = all_df[all_df[\"SalePrice\"].isnull()]\n\ntrain_df_le[\"SalePrice_log\"] = np.log(train_df_le[\"SalePrice\"])\ntrain_X = train_df_le.drop([\"SalePrice\", \"SalePrice_log\", \"Id\"], axis=1)\ntrain_Y = train_df_le[\"SalePrice_log\"]\n\n# p.239 得られたハイパーパラメータを設定してクロスバリデーション\n# 適用前 valid_0's l2: 0.0137713\n# 適用後 valid_0's l2: 0.0129672\nlgbm_params = {\n    'objective': 'regression',\n    'random_seed':1234,\n    'learning_rate':0.05,\n    'n_estimators':1000,\n    'num_leaves': 33,\n    'max_bin': 125,\n    'bagging_fraction': 0.7197362581993618,\n    'bagging_freq': 4,\n     'feature_fraction': 0.4684501358427995,\n     'min_data_in_leaf': 14,\n     'min_sum_hessian_in_leaf': 2\n}\n\n\nmodels = []\nrmses = []\noof = np.zeros(len(train_X))\n\nfor train_index, val_index in kf.split(train_X):\n    X_train = train_X.iloc[train_index]\n    X_valid = train_X.iloc[val_index]\n    y_train = train_Y.iloc[train_index]\n    y_valid = train_Y.iloc[val_index]\n    \n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n    \n    model_lgb = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval, num_boost_round=100, early_stopping_rounds=20, verbose_eval=10,)\n    \n    y_pred = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n    tmp_rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n    #print(tmp_rmse)\n    \n    models.append(model_lgb)\n    rmses.append(tmp_rmse)\n    oof[val_index] = y_pred\n\n# sum(rmses)/len(rmses)\n    \n# p.227 リスト4.57 時間に関する変数の統計量を確認\n#all_df[[\"YearBuilt\", \"YearRemodAdd\", \"GarageYrBlt\",\"YrSold\"]].describe()\n\n# p.229 リスト4.60 広さに関する変数の統計量を確認\n#all_df[[\"LotArea\", \"MasVnrArea\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"LowQualFinSF\", \"GrLivArea\", \"GarageArea\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\", \"ScreenPorch\", \"PoolArea\", \"LotFrontage\"]].describe()\n\n# p.241 Kaggleに結果をsubmitする\n","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:29:07.594067Z","iopub.execute_input":"2022-01-06T08:29:07.594362Z","iopub.status.idle":"2022-01-06T08:29:09.259451Z","shell.execute_reply.started":"2022-01-06T08:29:07.594331Z","shell.execute_reply":"2022-01-06T08:29:09.258789Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:256: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001908 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2374\n[LightGBM] [Info] Number of data points in the train set: 963, number of used features: 77\n[LightGBM] [Info] Start training from score 12.010615\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0730654\n[20]\tvalid_0's l2: 0.039388\n[30]\tvalid_0's l2: 0.0260691\n[40]\tvalid_0's l2: 0.019713\n[50]\tvalid_0's l2: 0.0167307\n[60]\tvalid_0's l2: 0.0153157\n[70]\tvalid_0's l2: 0.0145976\n[80]\tvalid_0's l2: 0.0141165\n[90]\tvalid_0's l2: 0.0139484\n[100]\tvalid_0's l2: 0.0137097\n[110]\tvalid_0's l2: 0.013655\n[120]\tvalid_0's l2: 0.0135674\n[130]\tvalid_0's l2: 0.0135293\n[140]\tvalid_0's l2: 0.0135037\n[150]\tvalid_0's l2: 0.0134944\n[160]\tvalid_0's l2: 0.013517\nEarly stopping, best iteration is:\n[143]\tvalid_0's l2: 0.0134783\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2370\n[LightGBM] [Info] Number of data points in the train set: 963, number of used features: 78\n[LightGBM] [Info] Start training from score 12.018820\nTraining until validation scores don't improve for 20 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[10]\tvalid_0's l2: 0.0833306\n[20]\tvalid_0's l2: 0.0493842\n[30]\tvalid_0's l2: 0.0337997\n[40]\tvalid_0's l2: 0.0266571\n[50]\tvalid_0's l2: 0.0230607\n[60]\tvalid_0's l2: 0.0214028\n[70]\tvalid_0's l2: 0.0202047\n[80]\tvalid_0's l2: 0.0195021\n[90]\tvalid_0's l2: 0.0189893\n[100]\tvalid_0's l2: 0.0187437\n[110]\tvalid_0's l2: 0.0185144\n[120]\tvalid_0's l2: 0.0184643\n[130]\tvalid_0's l2: 0.0183792\n[140]\tvalid_0's l2: 0.0183163\n[150]\tvalid_0's l2: 0.01836\n[160]\tvalid_0's l2: 0.0182416\n[170]\tvalid_0's l2: 0.0181873\n[180]\tvalid_0's l2: 0.0181668\n[190]\tvalid_0's l2: 0.0182043\n[200]\tvalid_0's l2: 0.0181913\nEarly stopping, best iteration is:\n[185]\tvalid_0's l2: 0.0181394\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2389\n[LightGBM] [Info] Number of data points in the train set: 964, number of used features: 78\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Start training from score 12.021869\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0672398\n[20]\tvalid_0's l2: 0.0368451\n[30]\tvalid_0's l2: 0.0242847\n[40]\tvalid_0's l2: 0.0184089\n[50]\tvalid_0's l2: 0.0157186\n[60]\tvalid_0's l2: 0.0144352\n[70]\tvalid_0's l2: 0.0138335\n[80]\tvalid_0's l2: 0.0135654\n[90]\tvalid_0's l2: 0.0134322\n[100]\tvalid_0's l2: 0.0133707\n[110]\tvalid_0's l2: 0.0132919\n[120]\tvalid_0's l2: 0.0131674\n[130]\tvalid_0's l2: 0.0130868\n[140]\tvalid_0's l2: 0.0130366\n[150]\tvalid_0's l2: 0.0129945\n[160]\tvalid_0's l2: 0.0130438\nEarly stopping, best iteration is:\n[144]\tvalid_0's l2: 0.0129672\n","output_type":"stream"}]},{"cell_type":"code","source":"# p.234 Optunaを実装する\n\n# p.235 リスト4.66 学習データと検証データを作成\nX_train, X_valid, y_train, y_valid = train_test_split(train_X, train_Y, test_size=0.2, random_state=1234, shuffle=False, stratify=None)\n\n# p.235 リスト4.67 Optunaでハイパーパラメータを最適化する\ndef objective(trial):\n    params = {\n        \"Objective\":\"regression\",\n        \"random_seed\":1234,\n        \"learning_rate\":0.05,\n        \"n_estimators\":1000,\n        \n        \"num_leaves\":trial.suggest_int(\"num_leaves\", 4, 64),\n        \"max_bin\":trial.suggest_int(\"max_bin\", 50, 200),\n        \"bagging_fraction\":trial.suggest_uniform(\"bagging_fraction\", 0.4, 0.9),\n        \"bagging_freq\":trial.suggest_int(\"bagging_freq\", 1, 10),\n        \"feature_fraction\":trial.suggest_uniform(\"feature_fraction\", 0.4, 0.9),\n        \"min_data_in_leaf\":trial.suggest_int(\"min_data_in_leaf\", 2, 16),\n        \"min_sum_hessian_in_leaf\":trial.suggest_int(\"min_sum_hessian_in_leaf\", 1, 10),\n    }\n    \n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n    \n    model_lgb = lgb.train(params, lgb_train, valid_sets=lgb_eval, num_boost_round=100, early_stopping_rounds=20, verbose_eval=10,)\n    \n    y_pred = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n    score = np.sqrt(mean_squared_error(y_valid, y_pred))\n    \n    return score\n\nstudy = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0))\nstudy.optimize(objective, n_trials=50)\nstudy.best_params\n","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:22:17.720290Z","iopub.execute_input":"2022-01-06T08:22:17.720602Z","iopub.status.idle":"2022-01-06T08:22:37.045273Z","shell.execute_reply.started":"2022-01-06T08:22:17.720560Z","shell.execute_reply":"2022-01-06T08:22:37.044586Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:17,736]\u001b[0m A new study created in memory with name: no-name-c744f4b5-48db-4264-98b6-0c95d1152d0e\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001389 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2805\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0659468\n[20]\tvalid_0's l2: 0.0360287\n[30]\tvalid_0's l2: 0.0239196\n[40]\tvalid_0's l2: 0.0183967\n[50]\tvalid_0's l2: 0.0161611\n[60]\tvalid_0's l2: 0.015461\n[70]\tvalid_0's l2: 0.0148438\n[80]\tvalid_0's l2: 0.0145826\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:18,125]\u001b[0m Trial 0 finished with value: 0.11921948775949834 and parameters: {'num_leaves': 37, 'max_bin': 157, 'bagging_fraction': 0.7013816880358219, 'bagging_freq': 6, 'feature_fraction': 0.6118273996694523, 'min_data_in_leaf': 11, 'min_sum_hessian_in_leaf': 5}. Best is trial 0 with value: 0.11921948775949834.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[90]\tvalid_0's l2: 0.0144628\n[100]\tvalid_0's l2: 0.0143176\n[110]\tvalid_0's l2: 0.0142316\n[120]\tvalid_0's l2: 0.0142159\n[130]\tvalid_0's l2: 0.0142722\nEarly stopping, best iteration is:\n[119]\tvalid_0's l2: 0.0142133\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001404 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 3097\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 20 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\tvalid_0's l2: 0.064469\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\tvalid_0's l2: 0.0353079\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\tvalid_0's l2: 0.0235852\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\tvalid_0's l2: 0.0183391\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\tvalid_0's l2: 0.0158484\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\tvalid_0's l2: 0.0148819\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\tvalid_0's l2: 0.0146264\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[80]\tvalid_0's l2: 0.0144416\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:18,505]\u001b[0m Trial 1 finished with value: 0.12012901418633552 and parameters: {'num_leaves': 58, 'max_bin': 195, 'bagging_fraction': 0.5917207594128888, 'bagging_freq': 8, 'feature_fraction': 0.6644474598764523, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 10}. Best is trial 0 with value: 0.11921948775949834.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[90]\tvalid_0's l2: 0.0144495\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[100]\tvalid_0's l2: 0.0145374\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[85]\tvalid_0's l2: 0.014431\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001396 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1571\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0723969\n[20]\tvalid_0's l2: 0.0430363\n[30]\tvalid_0's l2: 0.0303053\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n\u001b[32m[I 2022-01-06 08:22:18,707]\u001b[0m Trial 2 finished with value: 0.12243462195761393 and parameters: {'num_leaves': 8, 'max_bin': 63, 'bagging_fraction': 0.4101091987201629, 'bagging_freq': 9, 'feature_fraction': 0.7890783754749253, 'min_data_in_leaf': 15, 'min_sum_hessian_in_leaf': 10}. Best is trial 0 with value: 0.11921948775949834.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[40]\tvalid_0's l2: 0.0239242\n[50]\tvalid_0's l2: 0.0202706\n[60]\tvalid_0's l2: 0.0183297\n[70]\tvalid_0's l2: 0.0171541\n[80]\tvalid_0's l2: 0.0162883\n[90]\tvalid_0's l2: 0.0158127\n[100]\tvalid_0's l2: 0.0154521\n[110]\tvalid_0's l2: 0.0149976\n[120]\tvalid_0's l2: 0.0150278\n[130]\tvalid_0's l2: 0.0150877\nEarly stopping, best iteration is:\n[113]\tvalid_0's l2: 0.0149902\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001454 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2354\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0641327\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[20]\tvalid_0's l2: 0.034555\n[30]\tvalid_0's l2: 0.0232564\n[40]\tvalid_0's l2: 0.0185056\n[50]\tvalid_0's l2: 0.0165158\n[60]\tvalid_0's l2: 0.0155843\n[70]\tvalid_0's l2: 0.0151748\n[80]\tvalid_0's l2: 0.014894\n[90]\tvalid_0's l2: 0.0148207\n[100]\tvalid_0's l2: 0.0146971\n[110]\tvalid_0's l2: 0.0146044\n[120]\tvalid_0's l2: 0.0145469\n[130]\tvalid_0's l2: 0.0144888\n[140]\tvalid_0's l2: 0.0143614\n[150]\tvalid_0's l2: 0.014341\n[160]\tvalid_0's l2: 0.0143097\n[170]\tvalid_0's l2: 0.0143001\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:19,318]\u001b[0m Trial 3 finished with value: 0.11948763685441077 and parameters: {'num_leaves': 52, 'max_bin': 119, 'bagging_fraction': 0.7902645881432278, 'bagging_freq': 2, 'feature_fraction': 0.7199605106637619, 'min_data_in_leaf': 4, 'min_sum_hessian_in_leaf': 10}. Best is trial 0 with value: 0.11921948775949834.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[157]\tvalid_0's l2: 0.0142773\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001387 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2276\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.066408\n[20]\tvalid_0's l2: 0.0363539\n[30]\tvalid_0's l2: 0.0242351\n[40]\tvalid_0's l2: 0.0189323\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[50]\tvalid_0's l2: 0.0162179\n[60]\tvalid_0's l2: 0.0147991\n[70]\tvalid_0's l2: 0.0143232\n[80]\tvalid_0's l2: 0.0143152\n[90]\tvalid_0's l2: 0.0142693\n[100]\tvalid_0's l2: 0.0140259\n[110]\tvalid_0's l2: 0.0140546\n[120]\tvalid_0's l2: 0.0138189\n[130]\tvalid_0's l2: 0.0137193\n[140]\tvalid_0's l2: 0.0137243\n[150]\tvalid_0's l2: 0.0135936\n[160]\tvalid_0's l2: 0.0135242\n[170]\tvalid_0's l2: 0.0135713\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:19,741]\u001b[0m Trial 4 finished with value: 0.11621335807143585 and parameters: {'num_leaves': 35, 'max_bin': 112, 'bagging_fraction': 0.5322778060523135, 'bagging_freq': 8, 'feature_fraction': 0.6280751661082743, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 1}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[180]\tvalid_0's l2: 0.0136351\nEarly stopping, best iteration is:\n[161]\tvalid_0's l2: 0.0135055\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001420 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2626\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0639992\n[20]\tvalid_0's l2: 0.0357102\n[30]\tvalid_0's l2: 0.0236082\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n\u001b[32m[I 2022-01-06 08:22:20,101]\u001b[0m Trial 5 finished with value: 0.12288551018586134 and parameters: {'num_leaves': 41, 'max_bin': 142, 'bagging_fraction': 0.7084669984373785, 'bagging_freq': 10, 'feature_fraction': 0.7409101495517417, 'min_data_in_leaf': 7, 'min_sum_hessian_in_leaf': 5}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[40]\tvalid_0's l2: 0.0186928\n[50]\tvalid_0's l2: 0.016742\n[60]\tvalid_0's l2: 0.0157799\n[70]\tvalid_0's l2: 0.0155055\n[80]\tvalid_0's l2: 0.0152684\n[90]\tvalid_0's l2: 0.0151588\n[100]\tvalid_0's l2: 0.0151961\n[110]\tvalid_0's l2: 0.0152685\nEarly stopping, best iteration is:\n[94]\tvalid_0's l2: 0.0151008\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1500\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0650692\n[20]\tvalid_0's l2: 0.035213\n[30]\tvalid_0's l2: 0.0235695\n[40]\tvalid_0's l2: 0.0189368\n[50]\tvalid_0's l2: 0.0171787\n[60]\tvalid_0's l2: 0.0162984\n[70]\tvalid_0's l2: 0.0160839\n[80]\tvalid_0's l2: 0.0159674\n[90]\tvalid_0's l2: 0.0157391\n[100]\tvalid_0's l2: 0.0156661\n[110]\tvalid_0's l2: 0.015579\n[120]\tvalid_0's l2: 0.0154832\n[130]\tvalid_0's l2: 0.0153392\n[140]\tvalid_0's l2: 0.0153525\n[150]\tvalid_0's l2: 0.0153259\n[160]\tvalid_0's l2: 0.0153393\n[170]\tvalid_0's l2: 0.015381\nEarly stopping, best iteration is:\n[152]\tvalid_0's l2: 0.0153074\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:20,595]\u001b[0m Trial 6 finished with value: 0.12372288602804948 and parameters: {'num_leaves': 46, 'max_bin': 59, 'bagging_fraction': 0.7333833577228339, 'bagging_freq': 7, 'feature_fraction': 0.5051912805369205, 'min_data_in_leaf': 3, 'min_sum_hessian_in_leaf': 4}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2554\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0685588\n[20]\tvalid_0's l2: 0.0385705\n[30]\tvalid_0's l2: 0.0262354\n[40]\tvalid_0's l2: 0.0206248\n[50]\tvalid_0's l2: 0.017847\n[60]\tvalid_0's l2: 0.0167885\n[70]\tvalid_0's l2: 0.0160365\n[80]\tvalid_0's l2: 0.0157248\n[90]\tvalid_0's l2: 0.0156422\n[100]\tvalid_0's l2: 0.0155114\n[110]\tvalid_0's l2: 0.0154175","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:20,942]\u001b[0m Trial 7 finished with value: 0.12325661836479342 and parameters: {'num_leaves': 26, 'max_bin': 136, 'bagging_fraction': 0.6193007567311601, 'bagging_freq': 10, 'feature_fraction': 0.45102240537401406, 'min_data_in_leaf': 5, 'min_sum_hessian_in_leaf': 2}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\n[120]\tvalid_0's l2: 0.015317\n[130]\tvalid_0's l2: 0.0151995\n[140]\tvalid_0's l2: 0.0152626\n[150]\tvalid_0's l2: 0.0152446\nEarly stopping, best iteration is:\n[134]\tvalid_0's l2: 0.0151922\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000590 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1959\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[10]\tvalid_0's l2: 0.0653917\n[20]\tvalid_0's l2: 0.0353138\n[30]\tvalid_0's l2: 0.0236292\n[40]\tvalid_0's l2: 0.0191997\n[50]\tvalid_0's l2: 0.0170269\n[60]\tvalid_0's l2: 0.0159562\n[70]\tvalid_0's l2: 0.015702\n[80]\tvalid_0's l2: 0.0155463\n[90]\tvalid_0's l2: 0.0154414\n[100]\tvalid_0's l2: 0.0153966\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:21,442]\u001b[0m Trial 8 finished with value: 0.123200368396042 and parameters: {'num_leaves': 43, 'max_bin': 88, 'bagging_fraction': 0.6331553864281532, 'bagging_freq': 3, 'feature_fraction': 0.4794847918227599, 'min_data_in_leaf': 3, 'min_sum_hessian_in_leaf': 7}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[110]\tvalid_0's l2: 0.0153345\n[120]\tvalid_0's l2: 0.0152618\n[130]\tvalid_0's l2: 0.015293\n[140]\tvalid_0's l2: 0.0152435\n[150]\tvalid_0's l2: 0.0152064\n[160]\tvalid_0's l2: 0.0151995\n[170]\tvalid_0's l2: 0.0152254\nEarly stopping, best iteration is:\n[159]\tvalid_0's l2: 0.0151783\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1819\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0720131\n[20]\tvalid_0's l2: 0.0421651\n[30]\tvalid_0's l2: 0.0286681\n[40]\tvalid_0's l2: 0.0219793\n[50]\tvalid_0's l2: 0.0183408\n[60]\tvalid_0's l2: 0.0164611\n[70]\tvalid_0's l2: 0.01556\n[80]\tvalid_0's l2: 0.015073\n[90]\tvalid_0's l2: 0.0147495\n[100]\tvalid_0's l2: 0.0145849\n[110]\tvalid_0's l2: 0.0144036\n[120]\tvalid_0's l2: 0.014341\n[130]\tvalid_0's l2: 0.0143924\n[140]\tvalid_0's l2: 0.0141699\n[150]\tvalid_0's l2: 0.014075\n[160]\tvalid_0's l2: 0.0140664\n[170]\tvalid_0's l2: 0.0140677\n[180]\tvalid_0's l2: 0.0140645\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:21,731]\u001b[0m Trial 9 finished with value: 0.11833930321635734 and parameters: {'num_leaves': 12, 'max_bin': 79, 'bagging_fraction': 0.5843625853304821, 'bagging_freq': 9, 'feature_fraction': 0.44855063789653066, 'min_data_in_leaf': 14, 'min_sum_hessian_in_leaf': 1}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[164]\tvalid_0's l2: 0.0140042\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001448 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2368\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 80\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0645947\n[20]\tvalid_0's l2: 0.0349\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[30]\tvalid_0's l2: 0.0239167\n[40]\tvalid_0's l2: 0.019325\n[50]\tvalid_0's l2: 0.017922\n[60]\tvalid_0's l2: 0.017351\n[70]\tvalid_0's l2: 0.0171303\n[80]\tvalid_0's l2: 0.0171538\n[90]\tvalid_0's l2: 0.0170625\n[100]\tvalid_0's l2: 0.0169556\n[110]\tvalid_0's l2: 0.0169456\n[120]\tvalid_0's l2: 0.0168885\n[130]\tvalid_0's l2: 0.0168479\n[140]\tvalid_0's l2: 0.0168025\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:22,458]\u001b[0m Trial 10 finished with value: 0.1295435415929816 and parameters: {'num_leaves': 63, 'max_bin': 120, 'bagging_fraction': 0.8883805440951686, 'bagging_freq': 7, 'feature_fraction': 0.7696317896991509, 'min_data_in_leaf': 2, 'min_sum_hessian_in_leaf': 3}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[150]\tvalid_0's l2: 0.0167815\n[160]\tvalid_0's l2: 0.0168289\n[170]\tvalid_0's l2: 0.0168183\nEarly stopping, best iteration is:\n[150]\tvalid_0's l2: 0.0167815\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001427 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2051\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 80\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n\u001b[32m[I 2022-01-06 08:22:22,719]\u001b[0m Trial 11 finished with value: 0.11983377452964886 and parameters: {'num_leaves': 11, 'max_bin': 94, 'bagging_fraction': 0.45936385947712205, 'bagging_freq': 4, 'feature_fraction': 0.607131497257335, 'min_data_in_leaf': 2, 'min_sum_hessian_in_leaf': 7}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0723296\n[20]\tvalid_0's l2: 0.0424445\n[30]\tvalid_0's l2: 0.0284022\n[40]\tvalid_0's l2: 0.0222346\n[50]\tvalid_0's l2: 0.0189382\n[60]\tvalid_0's l2: 0.0171733\n[70]\tvalid_0's l2: 0.0163607\n[80]\tvalid_0's l2: 0.0154663\n[90]\tvalid_0's l2: 0.0151567\n[100]\tvalid_0's l2: 0.0149257\n[110]\tvalid_0's l2: 0.0147376\n[120]\tvalid_0's l2: 0.0145206\n[130]\tvalid_0's l2: 0.0145659\n[140]\tvalid_0's l2: 0.0145321\n[150]\tvalid_0's l2: 0.0144151\n[160]\tvalid_0's l2: 0.0143894\n[170]\tvalid_0's l2: 0.0144635\n[180]\tvalid_0's l2: 0.0146086\nEarly stopping, best iteration is:\n[163]\tvalid_0's l2: 0.0143601\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001512 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1987\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\tvalid_0's l2: 0.0652096\n[20]\tvalid_0's l2: 0.0355787\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\tvalid_0's l2: 0.0236788\n[40]\tvalid_0's l2: 0.0185916\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\tvalid_0's l2: 0.0165607\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\tvalid_0's l2: 0.0154825\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\tvalid_0's l2: 0.0149025\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[80]\tvalid_0's l2: 0.0146989\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[90]\tvalid_0's l2: 0.014613\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:23,033]\u001b[0m Trial 12 finished with value: 0.12066129587078789 and parameters: {'num_leaves': 38, 'max_bin': 90, 'bagging_fraction': 0.6616240267333499, 'bagging_freq': 1, 'feature_fraction': 0.6879732477780897, 'min_data_in_leaf': 15, 'min_sum_hessian_in_leaf': 4}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalid_0's l2: 0.014646\n[110]\tvalid_0's l2: 0.0146479\nEarly stopping, best iteration is:\n[92]\tvalid_0's l2: 0.0145591\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1665\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0675109\n[20]\tvalid_0's l2: 0.0373061\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[30]\tvalid_0's l2: 0.0244711\n[40]\tvalid_0's l2: 0.0192189\n[50]\tvalid_0's l2: 0.0169365\n[60]\tvalid_0's l2: 0.015945\n[70]\tvalid_0's l2: 0.0153745\n[80]\tvalid_0's l2: 0.0150851\n[90]\tvalid_0's l2: 0.014887\n[100]\tvalid_0's l2: 0.0147742\n[110]\tvalid_0's l2: 0.0146256\n[120]\tvalid_0's l2: 0.0146666\n[130]\tvalid_0's l2: 0.0145984\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:23,555]\u001b[0m Trial 13 finished with value: 0.1199504383453797 and parameters: {'num_leaves': 44, 'max_bin': 69, 'bagging_fraction': 0.7581636020592828, 'bagging_freq': 3, 'feature_fraction': 0.49159568100355844, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 1}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[140]\tvalid_0's l2: 0.014508\n[150]\tvalid_0's l2: 0.0144821\n[160]\tvalid_0's l2: 0.0144311\n[170]\tvalid_0's l2: 0.014398\n[180]\tvalid_0's l2: 0.0144176\n[190]\tvalid_0's l2: 0.0144799\nEarly stopping, best iteration is:\n[171]\tvalid_0's l2: 0.0143881\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1344\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 20 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\tvalid_0's l2: 0.0661537\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\tvalid_0's l2: 0.0357635\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\tvalid_0's l2: 0.0235315\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\tvalid_0's l2: 0.0184655\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\tvalid_0's l2: 0.016163\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\tvalid_0's l2: 0.0150688\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\tvalid_0's l2: 0.0146976\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[80]\tvalid_0's l2: 0.014342\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:23,953]\u001b[0m Trial 14 finished with value: 0.1183866598579404 and parameters: {'num_leaves': 54, 'max_bin': 50, 'bagging_fraction': 0.7389082683981151, 'bagging_freq': 3, 'feature_fraction': 0.7675970110612975, 'min_data_in_leaf': 16, 'min_sum_hessian_in_leaf': 3}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\n[90]\tvalid_0's l2: 0.0141401\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[100]\tvalid_0's l2: 0.0141325\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[110]\tvalid_0's l2: 0.0140446\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[120]\tvalid_0's l2: 0.0140154\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[130]\tvalid_0's l2: 0.0141523\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[140]\tvalid_0's l2: 0.0141645\nEarly stopping, best iteration is:\n[120]\tvalid_0's l2: 0.0140154\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001576 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2590\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0652192\n[20]\tvalid_0's l2: 0.0356203\n[30]\tvalid_0's l2: 0.023876\n[40]\tvalid_0's l2: 0.0188538\n[50]\tvalid_0's l2: 0.0170089\n[60]\tvalid_0's l2: 0.0161279\n[70]\tvalid_0's l2: 0.0157713\n[80]\tvalid_0's l2: 0.0154205\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:24,398]\u001b[0m Trial 15 finished with value: 0.12249843914982214 and parameters: {'num_leaves': 39, 'max_bin': 139, 'bagging_fraction': 0.6861259528954367, 'bagging_freq': 3, 'feature_fraction': 0.8763745057584925, 'min_data_in_leaf': 8, 'min_sum_hessian_in_leaf': 9}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[90]\tvalid_0's l2: 0.0153315\n[100]\tvalid_0's l2: 0.0151689\n[110]\tvalid_0's l2: 0.0150059\n[120]\tvalid_0's l2: 0.0150484\n[130]\tvalid_0's l2: 0.0150938\nEarly stopping, best iteration is:\n[110]\tvalid_0's l2: 0.0150059\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001558 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2047\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0654476\n[20]\tvalid_0's l2: 0.0348945\n[30]\tvalid_0's l2: 0.0232133\n[40]\tvalid_0's l2: 0.0186158\n[50]\tvalid_0's l2: 0.0167928\n[60]\tvalid_0's l2: 0.0158671\n[70]\tvalid_0's l2: 0.0151884\n[80]\tvalid_0's l2: 0.014973\n[90]\tvalid_0's l2: 0.0148574\n[100]\tvalid_0's l2: 0.0147908\n[110]\tvalid_0's l2: 0.0147467\n[120]\tvalid_0's l2: 0.0147442\n[130]\tvalid_0's l2: 0.0147911\n[140]\tvalid_0's l2: 0.0146097\n[150]\tvalid_0's l2: 0.0146298\n[160]\tvalid_0's l2: 0.0146584\nEarly stopping, best iteration is:\n[141]\tvalid_0's l2: 0.0145922\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:24,923]\u001b[0m Trial 16 finished with value: 0.12079833209560319 and parameters: {'num_leaves': 46, 'max_bin': 94, 'bagging_fraction': 0.8068989098512387, 'bagging_freq': 4, 'feature_fraction': 0.8405515985555808, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 9}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001580 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2827\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0635115\n[20]\tvalid_0's l2: 0.0356727\n[30]\tvalid_0's l2: 0.0241828\n[40]\tvalid_0's l2: 0.0197761\n[50]\tvalid_0's l2: 0.017458\n[60]\tvalid_0's l2: 0.0164014\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:25,290]\u001b[0m Trial 17 finished with value: 0.12465732708852482 and parameters: {'num_leaves': 46, 'max_bin': 159, 'bagging_fraction': 0.6506621909633512, 'bagging_freq': 10, 'feature_fraction': 0.7219950996148188, 'min_data_in_leaf': 8, 'min_sum_hessian_in_leaf': 7}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[70]\tvalid_0's l2: 0.0161523\n[80]\tvalid_0's l2: 0.015674\n[90]\tvalid_0's l2: 0.0155865\n[100]\tvalid_0's l2: 0.0156389\nEarly stopping, best iteration is:\n[85]\tvalid_0's l2: 0.0155394\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001590 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2060\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0772015\n[20]\tvalid_0's l2: 0.0488641\n[30]\tvalid_0's l2: 0.034581\n[40]\tvalid_0's l2: 0.0270809\n[50]\tvalid_0's l2: 0.0230393\n[60]\tvalid_0's l2: 0.020913\n[70]\tvalid_0's l2: 0.0198276\n[80]\tvalid_0's l2: 0.018913\n[90]\tvalid_0's l2: 0.0180636\n[100]\tvalid_0's l2: 0.0173222\n[110]\tvalid_0's l2: 0.0167365\n[120]\tvalid_0's l2: 0.0162763\n[130]\tvalid_0's l2: 0.016011\n[140]\tvalid_0's l2: 0.0157394\n[150]\tvalid_0's l2: 0.0154868\n[160]\tvalid_0's l2: 0.0154228\n[170]\tvalid_0's l2: 0.0153516\n[180]\tvalid_0's l2: 0.0152941\n[190]\tvalid_0's l2: 0.0150688\n[200]\tvalid_0's l2: 0.0149567\n[210]\tvalid_0's l2: 0.0148402\n[220]\tvalid_0's l2: 0.0148004\n[230]\tvalid_0's l2: 0.0146198\n[240]\tvalid_0's l2: 0.0145606\n[250]\tvalid_0's l2: 0.0145366\n[260]\tvalid_0's l2: 0.0144597\n[270]\tvalid_0's l2: 0.0144057\n[280]\tvalid_0's l2: 0.014351\n[290]\tvalid_0's l2: 0.0143398\n[300]\tvalid_0's l2: 0.0143803\nEarly stopping, best iteration is:\n[282]\tvalid_0's l2: 0.0143198\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:25,582]\u001b[0m Trial 18 finished with value: 0.11966528057480719 and parameters: {'num_leaves': 5, 'max_bin': 95, 'bagging_fraction': 0.7300867687463426, 'bagging_freq': 3, 'feature_fraction': 0.7090077144994208, 'min_data_in_leaf': 8, 'min_sum_hessian_in_leaf': 2}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001442 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2554\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0666045\n[20]\tvalid_0's l2: 0.037398\n[30]\tvalid_0's l2: 0.0252309\n[40]\tvalid_0's l2: 0.0194101\n[50]\tvalid_0's l2: 0.016904\n[60]\tvalid_0's l2: 0.0160305\n[70]\tvalid_0's l2: 0.0153439\n[80]\tvalid_0's l2: 0.0148304\n[90]\tvalid_0's l2: 0.0147109\n[100]\tvalid_0's l2: 0.0145076\n[110]\tvalid_0's l2: 0.0145036\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:25,907]\u001b[0m Trial 19 finished with value: 0.12002938223871082 and parameters: {'num_leaves': 22, 'max_bin': 136, 'bagging_fraction': 0.6954363806240866, 'bagging_freq': 6, 'feature_fraction': 0.7266004099285668, 'min_data_in_leaf': 11, 'min_sum_hessian_in_leaf': 5}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[120]\tvalid_0's l2: 0.0144584\n[130]\tvalid_0's l2: 0.0144166\n[140]\tvalid_0's l2: 0.0145413\n[150]\tvalid_0's l2: 0.0145218\nEarly stopping, best iteration is:\n[131]\tvalid_0's l2: 0.014407\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001411 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2182\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 20 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\tvalid_0's l2: 0.06419\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\tvalid_0's l2: 0.0359727\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\tvalid_0's l2: 0.0243612\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\tvalid_0's l2: 0.0194545\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\tvalid_0's l2: 0.0170943\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\tvalid_0's l2: 0.0163475\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\tvalid_0's l2: 0.015726\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[80]\tvalid_0's l2: 0.0156066\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[90]\tvalid_0's l2: 0.0155335\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[100]\tvalid_0's l2: 0.0155497\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[110]\tvalid_0's l2: 0.0154998\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[92]\tvalid_0's l2: 0.0154819\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:26,272]\u001b[0m Trial 20 finished with value: 0.12442620993318665 and parameters: {'num_leaves': 58, 'max_bin': 105, 'bagging_fraction': 0.6179324626328134, 'bagging_freq': 9, 'feature_fraction': 0.8030969945230428, 'min_data_in_leaf': 12, 'min_sum_hessian_in_leaf': 2}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001439 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2807\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0646566\n[20]\tvalid_0's l2: 0.0348004\n[30]\tvalid_0's l2: 0.023748\n[40]\tvalid_0's l2: 0.0194866\n[50]\tvalid_0's l2: 0.0176701\n[60]\tvalid_0's l2: 0.0170057\n[70]\tvalid_0's l2: 0.0167843\n[80]\tvalid_0's l2: 0.016537\n[90]\tvalid_0's l2: 0.0164991\n[100]\tvalid_0's l2: 0.0163692\n[110]\tvalid_0's l2: 0.0162118\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:26,861]\u001b[0m Trial 21 finished with value: 0.12718774119423695 and parameters: {'num_leaves': 60, 'max_bin': 157, 'bagging_fraction': 0.8994235032839333, 'bagging_freq': 2, 'feature_fraction': 0.8340630286841071, 'min_data_in_leaf': 4, 'min_sum_hessian_in_leaf': 7}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[120]\tvalid_0's l2: 0.0162129\n[130]\tvalid_0's l2: 0.0162495\nEarly stopping, best iteration is:\n[117]\tvalid_0's l2: 0.0161767\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001574 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 3017\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n\u001b[32m[I 2022-01-06 08:22:27,133]\u001b[0m Trial 22 finished with value: 0.12151261222488925 and parameters: {'num_leaves': 11, 'max_bin': 178, 'bagging_fraction': 0.8036594793625054, 'bagging_freq': 6, 'feature_fraction': 0.6035916486129999, 'min_data_in_leaf': 3, 'min_sum_hessian_in_leaf': 7}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[10]\tvalid_0's l2: 0.0717053\n[20]\tvalid_0's l2: 0.0413166\n[30]\tvalid_0's l2: 0.0279717\n[40]\tvalid_0's l2: 0.0219095\n[50]\tvalid_0's l2: 0.0189611\n[60]\tvalid_0's l2: 0.0172604\n[70]\tvalid_0's l2: 0.0164715\n[80]\tvalid_0's l2: 0.0160482\n[90]\tvalid_0's l2: 0.0157468\n[100]\tvalid_0's l2: 0.0153786\n[110]\tvalid_0's l2: 0.0151728\n[120]\tvalid_0's l2: 0.0149921\n[130]\tvalid_0's l2: 0.0149268\n[140]\tvalid_0's l2: 0.0148403\n[150]\tvalid_0's l2: 0.0148404\nEarly stopping, best iteration is:\n[137]\tvalid_0's l2: 0.0147653\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001575 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2831\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 80\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0656779\n[20]\tvalid_0's l2: 0.0362675\n[30]\tvalid_0's l2: 0.0243702\n[40]\tvalid_0's l2: 0.019556\n[50]\tvalid_0's l2: 0.0175464\n[60]\tvalid_0's l2: 0.0166221\n[70]\tvalid_0's l2: 0.016172\n[80]\tvalid_0's l2: 0.0160095\n[90]\tvalid_0's l2: 0.015721\n[100]\tvalid_0's l2: 0.0155644\n[110]\tvalid_0's l2: 0.0154965\n[120]\tvalid_0's l2: 0.0154206\n[130]\tvalid_0's l2: 0.0153846\n[140]\tvalid_0's l2: 0.0154011\n[150]\tvalid_0's l2: 0.0152218\n[160]\tvalid_0's l2: 0.0151882\n[170]\tvalid_0's l2: 0.0151679\n[180]\tvalid_0's l2: 0.0151587\n[190]\tvalid_0's l2: 0.0151501\n[200]\tvalid_0's l2: 0.0151077\n[210]\tvalid_0's l2: 0.0151401\n[220]\tvalid_0's l2: 0.0151285\n[230]\tvalid_0's l2: 0.015138\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:27,854]\u001b[0m Trial 23 finished with value: 0.12286137283920079 and parameters: {'num_leaves': 31, 'max_bin': 159, 'bagging_fraction': 0.8331911629643146, 'bagging_freq': 10, 'feature_fraction': 0.8279016711963055, 'min_data_in_leaf': 2, 'min_sum_hessian_in_leaf': 4}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[214]\tvalid_0's l2: 0.0150949\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1761\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 80\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0666495\n[20]\tvalid_0's l2: 0.0366255\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[30]\tvalid_0's l2: 0.0251371\n[40]\tvalid_0's l2: 0.0201572\n[50]\tvalid_0's l2: 0.0179482\n[60]\tvalid_0's l2: 0.0167342\n[70]\tvalid_0's l2: 0.0163499\n[80]\tvalid_0's l2: 0.0159761\n[90]\tvalid_0's l2: 0.0157986\n[100]\tvalid_0's l2: 0.0158269\n[110]\tvalid_0's l2: 0.015862\nEarly stopping, best iteration is:\n[91]\tvalid_0's l2: 0.0157823\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:28,248]\u001b[0m Trial 24 finished with value: 0.12562753706931873 and parameters: {'num_leaves': 48, 'max_bin': 75, 'bagging_fraction': 0.6605183031020647, 'bagging_freq': 1, 'feature_fraction': 0.49999826244820006, 'min_data_in_leaf': 2, 'min_sum_hessian_in_leaf': 8}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001644 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2158\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0688781\n[20]\tvalid_0's l2: 0.0382244\n[30]\tvalid_0's l2: 0.0256253\n[40]\tvalid_0's l2: 0.0200546\n[50]\tvalid_0's l2: 0.0173239\n[60]\tvalid_0's l2: 0.0160902\n[70]\tvalid_0's l2: 0.0154621\n[80]\tvalid_0's l2: 0.0150493\n[90]\tvalid_0's l2: 0.0148306\n[100]\tvalid_0's l2: 0.0145364\n[110]\tvalid_0's l2: 0.0144797\n[120]\tvalid_0's l2: 0.0143889\n[130]\tvalid_0's l2: 0.0142687\n[140]\tvalid_0's l2: 0.0141614\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:28,589]\u001b[0m Trial 25 finished with value: 0.11805245762386342 and parameters: {'num_leaves': 17, 'max_bin': 102, 'bagging_fraction': 0.8640406467327955, 'bagging_freq': 8, 'feature_fraction': 0.41591946476565395, 'min_data_in_leaf': 4, 'min_sum_hessian_in_leaf': 7}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[150]\tvalid_0's l2: 0.0140351\n[160]\tvalid_0's l2: 0.0139486\n[170]\tvalid_0's l2: 0.0139869\n[180]\tvalid_0's l2: 0.0139826\n[190]\tvalid_0's l2: 0.014061\nEarly stopping, best iteration is:\n[177]\tvalid_0's l2: 0.0139364\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001556 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1911\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0648772\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n\u001b[32m[I 2022-01-06 08:22:28,908]\u001b[0m Trial 26 finished with value: 0.1225406887451526 and parameters: {'num_leaves': 39, 'max_bin': 85, 'bagging_fraction': 0.867106998962397, 'bagging_freq': 7, 'feature_fraction': 0.6678164015124792, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 8}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[20]\tvalid_0's l2: 0.0348522\n[30]\tvalid_0's l2: 0.0229095\n[40]\tvalid_0's l2: 0.0183481\n[50]\tvalid_0's l2: 0.0164278\n[60]\tvalid_0's l2: 0.0157691\n[70]\tvalid_0's l2: 0.0153027\n[80]\tvalid_0's l2: 0.0150543\n[90]\tvalid_0's l2: 0.0150916\n[100]\tvalid_0's l2: 0.0152523\nEarly stopping, best iteration is:\n[85]\tvalid_0's l2: 0.0150162\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001455 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2251\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.066821\n[20]\tvalid_0's l2: 0.0369266\n[30]\tvalid_0's l2: 0.024767\n[40]\tvalid_0's l2: 0.0192622\n[50]\tvalid_0's l2: 0.0169376\n[60]\tvalid_0's l2: 0.0157414\n[70]\tvalid_0's l2: 0.0150072\n[80]\tvalid_0's l2: 0.0146723\n[90]\tvalid_0's l2: 0.0143443\n[100]\tvalid_0's l2: 0.0143655\n[110]\tvalid_0's l2: 0.0142893\nEarly stopping, best iteration is:\n[95]\tvalid_0's l2: 0.0142348\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:29,187]\u001b[0m Trial 27 finished with value: 0.11930966687202046 and parameters: {'num_leaves': 23, 'max_bin': 110, 'bagging_fraction': 0.5049218744875611, 'bagging_freq': 2, 'feature_fraction': 0.8721861949919668, 'min_data_in_leaf': 13, 'min_sum_hessian_in_leaf': 5}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001365 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1957\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0689996\n[20]\tvalid_0's l2: 0.0393946\n[30]\tvalid_0's l2: 0.026756\n[40]\tvalid_0's l2: 0.0207262\n[50]\tvalid_0's l2: 0.0181382\n[60]\tvalid_0's l2: 0.0163805\n[70]\tvalid_0's l2: 0.0155477\n[80]\tvalid_0's l2: 0.0151918\n[90]\tvalid_0's l2: 0.0149329\n[100]\tvalid_0's l2: 0.0144812\n[110]\tvalid_0's l2: 0.0143082\n[120]\tvalid_0's l2: 0.0142451\n[130]\tvalid_0's l2: 0.0142627\nEarly stopping, best iteration is:\n[114]\tvalid_0's l2: 0.0141747\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:29,430]\u001b[0m Trial 28 finished with value: 0.119057350011904 and parameters: {'num_leaves': 17, 'max_bin': 88, 'bagging_fraction': 0.42901458016193783, 'bagging_freq': 5, 'feature_fraction': 0.5558979409970513, 'min_data_in_leaf': 12, 'min_sum_hessian_in_leaf': 4}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1396\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0686203\n[20]\tvalid_0's l2: 0.0388643\n[30]\tvalid_0's l2: 0.0264241\n[40]\tvalid_0's l2: 0.0202205\n[50]\tvalid_0's l2: 0.0174781\n[60]\tvalid_0's l2: 0.015947\n[70]\tvalid_0's l2: 0.0152872\n[80]\tvalid_0's l2: 0.0148317\n[90]\tvalid_0's l2: 0.0145008\n[100]\tvalid_0's l2: 0.01441\n[110]\tvalid_0's l2: 0.014141\n[120]\tvalid_0's l2: 0.0140428\n[130]\tvalid_0's l2: 0.0139159\n[140]\tvalid_0's l2: 0.0137138\n[150]\tvalid_0's l2: 0.013781\n[160]\tvalid_0's l2: 0.0138249\nEarly stopping, best iteration is:\n[141]\tvalid_0's l2: 0.013665\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:29,676]\u001b[0m Trial 29 finished with value: 0.11689738493077198 and parameters: {'num_leaves': 14, 'max_bin': 53, 'bagging_fraction': 0.4336248157316243, 'bagging_freq': 7, 'feature_fraction': 0.6268484222780226, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 9}. Best is trial 4 with value: 0.11621335807143585.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001388 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1863\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 20 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\tvalid_0's l2: 0.0683398\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\tvalid_0's l2: 0.0372503\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\tvalid_0's l2: 0.0240048\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\tvalid_0's l2: 0.0186075\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\tvalid_0's l2: 0.0162722\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\tvalid_0's l2: 0.0148664\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\tvalid_0's l2: 0.0144529\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[80]\tvalid_0's l2: 0.0141959\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[90]\tvalid_0's l2: 0.0139596\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[100]\tvalid_0's l2: 0.0137909\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[110]\tvalid_0's l2: 0.0137427\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[120]\tvalid_0's l2: 0.013629\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[130]\tvalid_0's l2: 0.0136314\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[140]\tvalid_0's l2: 0.0135905\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[150]\tvalid_0's l2: 0.0135892\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[160]\tvalid_0's l2: 0.0135412\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[170]\tvalid_0's l2: 0.013555\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[180]\tvalid_0's l2: 0.0135165\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:30,218]\u001b[0m Trial 30 finished with value: 0.11621005960781597 and parameters: {'num_leaves': 64, 'max_bin': 82, 'bagging_fraction': 0.7315391015500504, 'bagging_freq': 3, 'feature_fraction': 0.41032549973286436, 'min_data_in_leaf': 13, 'min_sum_hessian_in_leaf': 4}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[190]\tvalid_0's l2: 0.0135885\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[200]\tvalid_0's l2: 0.0136354\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[181]\tvalid_0's l2: 0.0135048\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001388 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2578\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0662191\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[20]\tvalid_0's l2: 0.0375317\n[30]\tvalid_0's l2: 0.0249813\n[40]\tvalid_0's l2: 0.0196436\n[50]\tvalid_0's l2: 0.0175243\n[60]\tvalid_0's l2: 0.016674\n[70]\tvalid_0's l2: 0.0161567\n[80]\tvalid_0's l2: 0.0160406\n[90]\tvalid_0's l2: 0.0159134\n[100]\tvalid_0's l2: 0.0157352\n[110]\tvalid_0's l2: 0.0156062\n[120]\tvalid_0's l2: 0.0154926\n[130]\tvalid_0's l2: 0.0153928\n[140]\tvalid_0's l2: 0.015358\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:30,626]\u001b[0m Trial 31 finished with value: 0.12345973724558293 and parameters: {'num_leaves': 27, 'max_bin': 138, 'bagging_fraction': 0.8155242276180952, 'bagging_freq': 7, 'feature_fraction': 0.8363253277236977, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 8}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[150]\tvalid_0's l2: 0.0152489\n[160]\tvalid_0's l2: 0.0153489\n[170]\tvalid_0's l2: 0.0153372\nEarly stopping, best iteration is:\n[154]\tvalid_0's l2: 0.0152423\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001443 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 3081\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0687108\n[20]\tvalid_0's l2: 0.039362\n[30]\tvalid_0's l2: 0.0268704\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n\u001b[32m[I 2022-01-06 08:22:30,940]\u001b[0m Trial 32 finished with value: 0.12450060870067971 and parameters: {'num_leaves': 15, 'max_bin': 193, 'bagging_fraction': 0.7437441381939076, 'bagging_freq': 3, 'feature_fraction': 0.8736852952444621, 'min_data_in_leaf': 12, 'min_sum_hessian_in_leaf': 3}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[40]\tvalid_0's l2: 0.0213277\n[50]\tvalid_0's l2: 0.0185501\n[60]\tvalid_0's l2: 0.0172349\n[70]\tvalid_0's l2: 0.0165869\n[80]\tvalid_0's l2: 0.0160938\n[90]\tvalid_0's l2: 0.016112\n[100]\tvalid_0's l2: 0.0158469\n[110]\tvalid_0's l2: 0.0156173\n[120]\tvalid_0's l2: 0.0155477\n[130]\tvalid_0's l2: 0.01557\n[140]\tvalid_0's l2: 0.0155486\n[150]\tvalid_0's l2: 0.0155581\n[160]\tvalid_0's l2: 0.0155437\nEarly stopping, best iteration is:\n[144]\tvalid_0's l2: 0.0155004\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001451 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2459\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0682726\n[20]\tvalid_0's l2: 0.0384307\n[30]\tvalid_0's l2: 0.0260289\n[40]\tvalid_0's l2: 0.0204018\n[50]\tvalid_0's l2: 0.0177781\n[60]\tvalid_0's l2: 0.0165407\n[70]\tvalid_0's l2: 0.0158151\n[80]\tvalid_0's l2: 0.0154962\n[90]\tvalid_0's l2: 0.0152292\n[100]\tvalid_0's l2: 0.0150404\n[110]\tvalid_0's l2: 0.0148178\n[120]\tvalid_0's l2: 0.0148236\n[130]\tvalid_0's l2: 0.0146665\n[140]\tvalid_0's l2: 0.0146263\n[150]\tvalid_0's l2: 0.014627\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:31,248]\u001b[0m Trial 33 finished with value: 0.1207198568553516 and parameters: {'num_leaves': 17, 'max_bin': 128, 'bagging_fraction': 0.4128313590272658, 'bagging_freq': 3, 'feature_fraction': 0.6123427343757532, 'min_data_in_leaf': 7, 'min_sum_hessian_in_leaf': 5}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[160]\tvalid_0's l2: 0.0146223\n[170]\tvalid_0's l2: 0.0146368\nEarly stopping, best iteration is:\n[153]\tvalid_0's l2: 0.0145733\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001449 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2580\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0676655\n[20]\tvalid_0's l2: 0.0383163\n[30]\tvalid_0's l2: 0.0259987\n[40]\tvalid_0's l2: 0.0205822\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[50]\tvalid_0's l2: 0.0179582\n[60]\tvalid_0's l2: 0.0165008\n[70]\tvalid_0's l2: 0.0159439\n[80]\tvalid_0's l2: 0.0154322\n[90]\tvalid_0's l2: 0.0152\n[100]\tvalid_0's l2: 0.0150601\n[110]\tvalid_0's l2: 0.0149015\n[120]\tvalid_0's l2: 0.0147122\n[130]\tvalid_0's l2: 0.0146916\n[140]\tvalid_0's l2: 0.0146432\n[150]\tvalid_0's l2: 0.0145681\n[160]\tvalid_0's l2: 0.014555\n[170]\tvalid_0's l2: 0.0145766\n[180]\tvalid_0's l2: 0.0145195\n[190]\tvalid_0's l2: 0.0145071\n[200]\tvalid_0's l2: 0.0145429\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:31,660]\u001b[0m Trial 34 finished with value: 0.1203595765461759 and parameters: {'num_leaves': 20, 'max_bin': 138, 'bagging_fraction': 0.8319278029616157, 'bagging_freq': 2, 'feature_fraction': 0.6586895535770572, 'min_data_in_leaf': 3, 'min_sum_hessian_in_leaf': 8}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[186]\tvalid_0's l2: 0.0144864\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2542\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.068393\n[20]\tvalid_0's l2: 0.0381795\n[30]\tvalid_0's l2: 0.0252867\n[40]\tvalid_0's l2: 0.0199694\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n\u001b[32m[I 2022-01-06 08:22:31,975]\u001b[0m Trial 35 finished with value: 0.12059170214927306 and parameters: {'num_leaves': 28, 'max_bin': 135, 'bagging_fraction': 0.49163991810703933, 'bagging_freq': 2, 'feature_fraction': 0.6440281403244773, 'min_data_in_leaf': 7, 'min_sum_hessian_in_leaf': 10}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[50]\tvalid_0's l2: 0.017562\n[60]\tvalid_0's l2: 0.0163758\n[70]\tvalid_0's l2: 0.0155249\n[80]\tvalid_0's l2: 0.0149318\n[90]\tvalid_0's l2: 0.0147414\n[100]\tvalid_0's l2: 0.0146293\n[110]\tvalid_0's l2: 0.0146798\n[120]\tvalid_0's l2: 0.0146872\nEarly stopping, best iteration is:\n[105]\tvalid_0's l2: 0.0145424\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001448 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2870","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.064695\n[20]\tvalid_0's l2: 0.0350467\n[30]\tvalid_0's l2: 0.0236307\n[40]\tvalid_0's l2: 0.0190976\n[50]\tvalid_0's l2: 0.0170016\n[60]\tvalid_0's l2: 0.0162354\n[70]\tvalid_0's l2: 0.0158601\n[80]\tvalid_0's l2: 0.0156705\n[90]\tvalid_0's l2: 0.0155466\n[100]\tvalid_0's l2: 0.0154278\n[110]\tvalid_0's l2: 0.0153874\n[120]\tvalid_0's l2: 0.0153315\n[130]\tvalid_0's l2: 0.0153339\n[140]\tvalid_0's l2: 0.0153313\n[150]\tvalid_0's l2: 0.0153087\n[160]\tvalid_0's l2: 0.0153258\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:32,503]\u001b[0m Trial 36 finished with value: 0.12362844403791992 and parameters: {'num_leaves': 50, 'max_bin': 163, 'bagging_fraction': 0.8518598698729667, 'bagging_freq': 1, 'feature_fraction': 0.6760962349612033, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 10}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[145]\tvalid_0's l2: 0.015284\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001444 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1928\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0677306\n[20]\tvalid_0's l2: 0.0370913\n[30]\tvalid_0's l2: 0.0243411\n[40]\tvalid_0's l2: 0.0191862\n[50]\tvalid_0's l2: 0.0167617\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n\u001b[32m[I 2022-01-06 08:22:32,853]\u001b[0m Trial 37 finished with value: 0.11634589292845095 and parameters: {'num_leaves': 21, 'max_bin': 86, 'bagging_fraction': 0.45014697113274893, 'bagging_freq': 1, 'feature_fraction': 0.8647646583960953, 'min_data_in_leaf': 12, 'min_sum_hessian_in_leaf': 8}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[60]\tvalid_0's l2: 0.0155816\n[70]\tvalid_0's l2: 0.0147963\n[80]\tvalid_0's l2: 0.0142493\n[90]\tvalid_0's l2: 0.0141046\n[100]\tvalid_0's l2: 0.01402\n[110]\tvalid_0's l2: 0.01378\n[120]\tvalid_0's l2: 0.013896\n[130]\tvalid_0's l2: 0.0137337\n[140]\tvalid_0's l2: 0.0136708\n[150]\tvalid_0's l2: 0.013656\n[160]\tvalid_0's l2: 0.0135364\n[170]\tvalid_0's l2: 0.0136163\n[180]\tvalid_0's l2: 0.013646\nEarly stopping, best iteration is:\n[160]\tvalid_0's l2: 0.0135364\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000718 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2578\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0683957\n[20]\tvalid_0's l2: 0.0389712\n[30]\tvalid_0's l2: 0.0265129\n[40]\tvalid_0's l2: 0.0206742\n[50]\tvalid_0's l2: 0.0187495\n[60]\tvalid_0's l2: 0.0173362\n[70]\tvalid_0's l2: 0.0164796\n[80]\tvalid_0's l2: 0.0159671\n[90]\tvalid_0's l2: 0.0157594\n[100]\tvalid_0's l2: 0.0153507\n[110]\tvalid_0's l2: 0.0150858\n[120]\tvalid_0's l2: 0.014961\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:33,179]\u001b[0m Trial 38 finished with value: 0.12190846996739746 and parameters: {'num_leaves': 21, 'max_bin': 138, 'bagging_fraction': 0.4319776330604906, 'bagging_freq': 5, 'feature_fraction': 0.8887475698722234, 'min_data_in_leaf': 15, 'min_sum_hessian_in_leaf': 4}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[130]\tvalid_0's l2: 0.01496\n[140]\tvalid_0's l2: 0.0148748\n[150]\tvalid_0's l2: 0.014995\n[160]\tvalid_0's l2: 0.0149387\nEarly stopping, best iteration is:\n[141]\tvalid_0's l2: 0.0148617\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001437 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1896\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0644176\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[20]\tvalid_0's l2: 0.0351717\n[30]\tvalid_0's l2: 0.0235163\n[40]\tvalid_0's l2: 0.0193476\n[50]\tvalid_0's l2: 0.0170961\n[60]\tvalid_0's l2: 0.0161074\n[70]\tvalid_0's l2: 0.0154883\n[80]\tvalid_0's l2: 0.0152515\n[90]\tvalid_0's l2: 0.015119\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:33,681]\u001b[0m Trial 39 finished with value: 0.12215065383271784 and parameters: {'num_leaves': 62, 'max_bin': 84, 'bagging_fraction': 0.8746594112078407, 'bagging_freq': 10, 'feature_fraction': 0.7996012936761958, 'min_data_in_leaf': 11, 'min_sum_hessian_in_leaf': 9}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalid_0's l2: 0.0150402\n[110]\tvalid_0's l2: 0.0149841\n[120]\tvalid_0's l2: 0.0149376\n[130]\tvalid_0's l2: 0.0150143\n[140]\tvalid_0's l2: 0.015119\nEarly stopping, best iteration is:\n[122]\tvalid_0's l2: 0.0149208\n[LightGBM] [Warning] Unknown parameter: Objective\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001414 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 3017\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.067131\n[20]\tvalid_0's l2: 0.037303\n[30]\tvalid_0's l2: 0.0249732\n[40]\tvalid_0's l2: 0.0195751\n[50]\tvalid_0's l2: 0.0168822\n[60]\tvalid_0's l2: 0.0154761\n[70]\tvalid_0's l2: 0.0148505\n[80]\tvalid_0's l2: 0.0144755\n[90]\tvalid_0's l2: 0.014292\n[100]\tvalid_0's l2: 0.0141133\n[110]\tvalid_0's l2: 0.0140325\n[120]\tvalid_0's l2: 0.0138918\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:34,040]\u001b[0m Trial 40 finished with value: 0.1170233190753309 and parameters: {'num_leaves': 21, 'max_bin': 178, 'bagging_fraction': 0.7089383459587619, 'bagging_freq': 1, 'feature_fraction': 0.5736167589661099, 'min_data_in_leaf': 4, 'min_sum_hessian_in_leaf': 10}. Best is trial 30 with value: 0.11621005960781597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[130]\tvalid_0's l2: 0.0138017\n[140]\tvalid_0's l2: 0.0137878\n[150]\tvalid_0's l2: 0.0137468\n[160]\tvalid_0's l2: 0.0137043\n[170]\tvalid_0's l2: 0.0137\n[180]\tvalid_0's l2: 0.0137556\nEarly stopping, best iteration is:\n[161]\tvalid_0's l2: 0.0136945\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000604 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2424\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[10]\tvalid_0's l2: 0.0680019\n[20]\tvalid_0's l2: 0.0374251\n[30]\tvalid_0's l2: 0.0246349\n[40]\tvalid_0's l2: 0.019427\n[50]\tvalid_0's l2: 0.0167085\n[60]\tvalid_0's l2: 0.0151676\n[70]\tvalid_0's l2: 0.014551\n[80]\tvalid_0's l2: 0.0141983\n[90]\tvalid_0's l2: 0.0139977\n[100]\tvalid_0's l2: 0.0139503\n[110]\tvalid_0's l2: 0.0138424\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:34,474]\u001b[0m Trial 41 finished with value: 0.11607389645958345 and parameters: {'num_leaves': 33, 'max_bin': 125, 'bagging_fraction': 0.7197362581993618, 'bagging_freq': 4, 'feature_fraction': 0.4684501358427995, 'min_data_in_leaf': 14, 'min_sum_hessian_in_leaf': 2}. Best is trial 41 with value: 0.11607389645958345.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[120]\tvalid_0's l2: 0.0136913\n[130]\tvalid_0's l2: 0.0136268\n[140]\tvalid_0's l2: 0.0135483\n[150]\tvalid_0's l2: 0.0134731\n[160]\tvalid_0's l2: 0.0135188\n[170]\tvalid_0's l2: 0.0135685\nEarly stopping, best iteration is:\n[150]\tvalid_0's l2: 0.0134731\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1876\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 20 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\tvalid_0's l2: 0.0678542\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\tvalid_0's l2: 0.0378289\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\tvalid_0's l2: 0.0261082\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\tvalid_0's l2: 0.0210435\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\tvalid_0's l2: 0.0184464\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[60]\tvalid_0's l2: 0.0171952\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[70]\tvalid_0's l2: 0.0167112\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[80]\tvalid_0's l2: 0.0160407\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[90]\tvalid_0's l2: 0.0156498\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[100]\tvalid_0's l2: 0.0156878\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[110]\tvalid_0's l2: 0.01528\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[120]\tvalid_0's l2: 0.0155507\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[130]\tvalid_0's l2: 0.0155976\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[111]\tvalid_0's l2: 0.0152782\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:34,776]\u001b[0m Trial 42 finished with value: 0.12360509389043547 and parameters: {'num_leaves': 35, 'max_bin': 83, 'bagging_fraction': 0.44892224224701704, 'bagging_freq': 9, 'feature_fraction': 0.8864597445115652, 'min_data_in_leaf': 16, 'min_sum_hessian_in_leaf': 10}. Best is trial 41 with value: 0.11607389645958345.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2132\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0664833\n[20]\tvalid_0's l2: 0.0369944\n[30]\tvalid_0's l2: 0.0252167\n[40]\tvalid_0's l2: 0.0195319\n[50]\tvalid_0's l2: 0.0176001\n[60]\tvalid_0's l2: 0.0164878\n[70]\tvalid_0's l2: 0.0160626\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:35,183]\u001b[0m Trial 43 finished with value: 0.12258004859678505 and parameters: {'num_leaves': 51, 'max_bin': 100, 'bagging_fraction': 0.4405506949939984, 'bagging_freq': 5, 'feature_fraction': 0.5161170710854714, 'min_data_in_leaf': 3, 'min_sum_hessian_in_leaf': 1}. Best is trial 41 with value: 0.11607389645958345.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[80]\tvalid_0's l2: 0.0157654\n[90]\tvalid_0's l2: 0.0154859\n[100]\tvalid_0's l2: 0.0151975\n[110]\tvalid_0's l2: 0.0150395\n[120]\tvalid_0's l2: 0.0150358\nEarly stopping, best iteration is:\n[107]\tvalid_0's l2: 0.0150259\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1364\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0671077\n[20]\tvalid_0's l2: 0.0359559\n[30]\tvalid_0's l2: 0.0239904\n[40]\tvalid_0's l2: 0.0189382\n[50]\tvalid_0's l2: 0.0167995\n[60]\tvalid_0's l2: 0.0154498\n[70]\tvalid_0's l2: 0.0148961\n[80]\tvalid_0's l2: 0.0147326\n[90]\tvalid_0's l2: 0.0146315\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:35,617]\u001b[0m Trial 44 finished with value: 0.1184374572828425 and parameters: {'num_leaves': 48, 'max_bin': 51, 'bagging_fraction': 0.7852903742513881, 'bagging_freq': 2, 'feature_fraction': 0.4397610412933779, 'min_data_in_leaf': 3, 'min_sum_hessian_in_leaf': 7}. Best is trial 41 with value: 0.11607389645958345.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalid_0's l2: 0.014387\n[110]\tvalid_0's l2: 0.014218\n[120]\tvalid_0's l2: 0.0140993\n[130]\tvalid_0's l2: 0.0140685\n[140]\tvalid_0's l2: 0.0140959\nEarly stopping, best iteration is:\n[126]\tvalid_0's l2: 0.0140274\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001424 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2289\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0676824\n[20]\tvalid_0's l2: 0.0391645\n[30]\tvalid_0's l2: 0.0265916\n[40]\tvalid_0's l2: 0.0210271\n[50]\tvalid_0's l2: 0.0183889\n[60]\tvalid_0's l2: 0.01707\n[70]\tvalid_0's l2: 0.0163417\n[80]\tvalid_0's l2: 0.0159728\n[90]\tvalid_0's l2: 0.0156951\n[100]\tvalid_0's l2: 0.0156128\n[110]\tvalid_0's l2: 0.0153255\n[120]\tvalid_0's l2: 0.0152131\n[130]\tvalid_0's l2: 0.0151542\nEarly stopping, best iteration is:\n[117]\tvalid_0's l2: 0.0151455\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:35,898]\u001b[0m Trial 45 finished with value: 0.12306701064230102 and parameters: {'num_leaves': 18, 'max_bin': 113, 'bagging_fraction': 0.6786843956619585, 'bagging_freq': 9, 'feature_fraction': 0.7635221313556642, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 2}. Best is trial 41 with value: 0.11607389645958345.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001392 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2060\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0736703\n[20]\tvalid_0's l2: 0.0446699\n[30]\tvalid_0's l2: 0.0309675\n[40]\tvalid_0's l2: 0.0240148\n[50]\tvalid_0's l2: 0.0205786\n[60]\tvalid_0's l2: 0.0184582\n[70]\tvalid_0's l2: 0.0172221\n[80]\tvalid_0's l2: 0.0162455\n[90]\tvalid_0's l2: 0.0157497\n[100]\tvalid_0's l2: 0.0152315\n[110]\tvalid_0's l2: 0.0152008\n[120]\tvalid_0's l2: 0.0152169\n[130]\tvalid_0's l2: 0.0149349\n[140]\tvalid_0's l2: 0.0147038\n[150]\tvalid_0's l2: 0.0146566\n[160]\tvalid_0's l2: 0.0145811\n[170]\tvalid_0's l2: 0.0146407\n[180]\tvalid_0's l2: 0.0145551\n[190]\tvalid_0's l2: 0.0145977\n[200]\tvalid_0's l2: 0.0145908\nEarly stopping, best iteration is:\n[185]\tvalid_0's l2: 0.0145195\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:36,139]\u001b[0m Trial 46 finished with value: 0.12049687664013224 and parameters: {'num_leaves': 7, 'max_bin': 95, 'bagging_fraction': 0.5310590746198391, 'bagging_freq': 5, 'feature_fraction': 0.7416406677738403, 'min_data_in_leaf': 12, 'min_sum_hessian_in_leaf': 3}. Best is trial 41 with value: 0.11607389645958345.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1789\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0664059\n[20]\tvalid_0's l2: 0.0364447\n[30]\tvalid_0's l2: 0.0245169\n[40]\tvalid_0's l2: 0.0195329\n[50]\tvalid_0's l2: 0.0173828\n[60]\tvalid_0's l2: 0.0164353\n[70]\tvalid_0's l2: 0.0157514\n[80]\tvalid_0's l2: 0.0153623\n[90]\tvalid_0's l2: 0.015229\n[100]\tvalid_0's l2: 0.0151322\n[110]\tvalid_0's l2: 0.0149309\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:36,460]\u001b[0m Trial 47 finished with value: 0.12172000179946446 and parameters: {'num_leaves': 27, 'max_bin': 77, 'bagging_fraction': 0.7942727561532594, 'bagging_freq': 1, 'feature_fraction': 0.7484986208624937, 'min_data_in_leaf': 13, 'min_sum_hessian_in_leaf': 8}. Best is trial 41 with value: 0.11607389645958345.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[120]\tvalid_0's l2: 0.0148238\n[130]\tvalid_0's l2: 0.0148456\n[140]\tvalid_0's l2: 0.0148433\nEarly stopping, best iteration is:\n[122]\tvalid_0's l2: 0.0148158\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000551 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2198\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 79\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0674904\n[20]\tvalid_0's l2: 0.0378495\n[30]\tvalid_0's l2: 0.0253106\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n\u001b[32m[I 2022-01-06 08:22:36,791]\u001b[0m Trial 48 finished with value: 0.12038292521465738 and parameters: {'num_leaves': 19, 'max_bin': 106, 'bagging_fraction': 0.6937998175981945, 'bagging_freq': 3, 'feature_fraction': 0.5854263996089444, 'min_data_in_leaf': 4, 'min_sum_hessian_in_leaf': 5}. Best is trial 41 with value: 0.11607389645958345.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[40]\tvalid_0's l2: 0.0199075\n[50]\tvalid_0's l2: 0.0172684\n[60]\tvalid_0's l2: 0.0158523\n[70]\tvalid_0's l2: 0.0153712\n[80]\tvalid_0's l2: 0.0151057\n[90]\tvalid_0's l2: 0.0150663\n[100]\tvalid_0's l2: 0.014961\n[110]\tvalid_0's l2: 0.0148236\n[120]\tvalid_0's l2: 0.0147344\n[130]\tvalid_0's l2: 0.0146849\n[140]\tvalid_0's l2: 0.014542\n[150]\tvalid_0's l2: 0.0146394\n[160]\tvalid_0's l2: 0.0146166\nEarly stopping, best iteration is:\n[144]\tvalid_0's l2: 0.014492\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n  _log_warning('Overriding the parameters from Reference Dataset.')\n/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n  _log_warning(f'{cat_alias} in param dict is overridden.')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001415 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2940\n[LightGBM] [Info] Number of data points in the train set: 1156, number of used features: 78\n[LightGBM] [Warning] Unknown parameter: Objective\n[LightGBM] [Info] Start training from score 12.015333\nTraining until validation scores don't improve for 20 rounds\n[10]\tvalid_0's l2: 0.0762818\n[20]\tvalid_0's l2: 0.0467362\n[30]\tvalid_0's l2: 0.03249\n[40]\tvalid_0's l2: 0.0257868\n[50]\tvalid_0's l2: 0.0214988\n[60]\tvalid_0's l2: 0.0193962\n[70]\tvalid_0's l2: 0.0180176\n[80]\tvalid_0's l2: 0.0166924\n[90]\tvalid_0's l2: 0.015955\n[100]\tvalid_0's l2: 0.0155308\n[110]\tvalid_0's l2: 0.0151824\n[120]\tvalid_0's l2: 0.0147177\n[130]\tvalid_0's l2: 0.0146438\n[140]\tvalid_0's l2: 0.0145239\n[150]\tvalid_0's l2: 0.014505\n[160]\tvalid_0's l2: 0.0145101\n[170]\tvalid_0's l2: 0.0143538\n[180]\tvalid_0's l2: 0.0142652\n[190]\tvalid_0's l2: 0.0142552\n[200]\tvalid_0's l2: 0.0142293\n[210]\tvalid_0's l2: 0.0140382\n[220]\tvalid_0's l2: 0.0142292\n[230]\tvalid_0's l2: 0.0141861\nEarly stopping, best iteration is:\n[210]\tvalid_0's l2: 0.0140382\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-01-06 08:22:37,031]\u001b[0m Trial 49 finished with value: 0.11848287385526712 and parameters: {'num_leaves': 6, 'max_bin': 170, 'bagging_fraction': 0.4384782234933164, 'bagging_freq': 6, 'feature_fraction': 0.5534050497725981, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 10}. Best is trial 41 with value: 0.11607389645958345.\u001b[0m\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'num_leaves': 33,\n 'max_bin': 125,\n 'bagging_fraction': 0.7197362581993618,\n 'bagging_freq': 4,\n 'feature_fraction': 0.4684501358427995,\n 'min_data_in_leaf': 14,\n 'min_sum_hessian_in_leaf': 2}"},"metadata":{}}]}]}